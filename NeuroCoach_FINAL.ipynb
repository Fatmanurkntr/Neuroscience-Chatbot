{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #282c34; padding: 20px; border-radius: 10px; border: 1px solid #61afef;\">\n",
        "<!-- BAŞLIĞI BÜYÜTMEK İÇİN font-size DEĞERİNİ ARTIRDIK -->\n",
        "<h1 style=\"color: #61afef; font-size: 32px; text-align: center; border-bottom: 2px solid #61afef; padding-bottom: 10px; margin-top: 0; text-shadow: 2px 2px 5px rgba(0,0,0,0.3);\">\n",
        "🧠 Bölüm 1: Proje Ortamının Kurulumu\n",
        "</h1>\n",
        "<p style=\"font-size: 16px;\">Bu bölümde, <strong>Nörobilim Asistanı</strong> projemizin çalışması için gerekli olan tüm temel altyapıyı hazırlayacağız. Süreç, projemizin sağlam bir temel üzerine inşa edilmesini sağlayan iki kritik adımdan oluşur.</p>\n",
        "<h3 style=\"color: #e5c07b;\">1.1. Gerekli Kütüphanelerin Yüklenmesi <font color=\"#98c379\">📚</font></h3>\n",
        "<p>Projemizin bel kemiğini oluşturan Python kütüphanelerini Colab ortamına kuruyoruz. Bu adımda, tüm bileşenlerin birbiriyle uyumlu çalışmasını garantileyen belirli versiyonlar ve kurulum yöntemleri kullanıyoruz.</p>\n",
        "<ul>\n",
        "<li><font color=\"#61afef\"><strong>LangChain & Ekosistemi:</strong></font> RAG mimarisini ve chatbot'un ana mantığını (zincirler, hafıza vb.) oluşturmak için.</li>\n",
        "<li><font color=\"#c678dd\"><strong>Google Generative AI:</strong></font> Projemizin \"düşünen beyni\" olan güçlü <code>Gemini</code> dil modelini kullanabilmek için.</li>\n",
        "<li><font color=\"#e5c07b\"><strong>Vektör Veritabanı:</strong></font> <code>ChromaDB</code> ve ilgili <code>LangChain</code> entegrasyonları, bilgi bankamızı verimli bir şekilde saklamak ve içinde anlamsal arama yapmak için.</li>\n",
        "<li><font color=\"#e06c75\"><strong>Hugging Face:</strong></font> Metinleri matematiksel olarak anlaşılabilir vektörlere dönüştüren <code>embedding</code> modelini çekmek için.</li>\n",
        "</ul>\n",
        "<br>\n",
        "<h3 style=\"color: #e5c07b;\">1.2. Kurulum Doğrulaması <font color=\"#98c379\">✅</font></h3>\n",
        "<p>Kurulum tamamlandıktan sonra, yüklenen tüm kütüphanelerin Python tarafından doğru bir şekilde tanınıp tanınmadığını bir <code>import</code> testi ile kontrol ediyoruz.</p>\n",
        "<blockquote style=\"border-left: 4px solid #56b6c2; padding-left: 15px; margin: 10px 0; color: #abb2bf;\">\n",
        "🚀 Bu testin başarıyla geçmesi, geliştirme ortamımızın <strong>sağlıklı</strong> ve projenin geri kalanına başlamak için <strong>hazır</strong> olduğunu doğrular.\n",
        "</blockquote>\n",
        "</div>"
      ],
      "metadata": {
        "id": "VUwnvUYaWYJG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1Zv5eikaMLd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b67bde62-388a-43f3-f4e0-cf36affbc656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ADIM 1: Gerekli modern kütüphaneler yükleniyor... ---\n",
            "✅ Kurulum tamamlandı ve Colab ile uyumlu hale getirildi.\n",
            "\n",
            "--- ADIM 2: Güncel import testi ---\n",
            "✅ Tüm import'lar başarıyla yüklendi! Ortam temiz ve uyumlu 🚀\n"
          ]
        }
      ],
      "source": [
        "print(\"--- ADIM 1: Gerekli modern kütüphaneler yükleniyor... ---\")\n",
        "!pip install -U -q \\\n",
        "    langchain \\\n",
        "    langchain-core \\\n",
        "    langchain-community \\\n",
        "    langchain-chroma \\\n",
        "    langchain-huggingface \\\n",
        "    langchain-text-splitters \\\n",
        "    langchain-google-genai \\\n",
        "    chromadb \\\n",
        "    datasets \\\n",
        "    google-generativeai==0.8.5 \\\n",
        "    pandas==2.2.2 \\\n",
        "    requests==2.32.4 \\\n",
        "    gradio\n",
        "\n",
        "print(\"✅ Kurulum tamamlandı ve Colab ile uyumlu hale getirildi.\")\n",
        "\n",
        "print(\"\\n--- ADIM 2: Güncel import testi ---\")\n",
        "try:\n",
        "    import os, time, gradio as gr, pandas as pd, google.generativeai as genai\n",
        "    from datasets import load_dataset\n",
        "    from langchain_chroma import Chroma\n",
        "    from langchain_huggingface import HuggingFaceEmbeddings\n",
        "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "    from langchain.memory import ConversationBufferMemory\n",
        "    from langchain.prompts import ChatPromptTemplate\n",
        "    from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "    from langchain.chains import create_retrieval_chain\n",
        "    print(\"✅ Tüm import'lar başarıyla yüklendi! Ortam temiz ve uyumlu 🚀\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Import hatası: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #282c34; padding: 20px; border-radius: 10px; border: 1px solid #c678dd;\">\n",
        "<h1 style=\"color: #c678dd; font-size: 32px; text-align: center; border-bottom: 2px solid #c678dd; padding-bottom: 10px; margin-top: 0; text-shadow: 2px 2px 5px rgba(0,0,0,0.3);\">\n",
        "🔑 Bölüm 1.2: API Yapılandırması ve Model Testi\n",
        "</h1>\n",
        "<p style=\"font-size: 16px;\">Kütüphaneleri kurduktan sonraki bu kritik adımda, projemize Google'ın güçlü yapay zeka modellerini kullanma yetkisi veriyoruz.</p>\n",
        "<h3 style=\"color: #e5c07b;\">API Anahtarı Yapılandırması <font color=\"#e06c75\">🔐</font></h3>\n",
        "<p>API anahtarımızı doğrudan kodun içine yazmak yerine, Colab'in güvenli <code>Secrets</code> (Gizli Anahtarlar) özelliğini kullanarak <code>GOOGLE_API_KEY</code> adıyla sakladığımız anahtarı çekiyoruz. Bu yöntem, anahtarımızın gizli ve güvende kalmasını sağlar. <code>genai.configure()</code> fonksiyonu ile bu anahtarı kullanarak Google servisleriyle güvenli bir bağlantı kuruyoruz.</p>\n",
        "<br>\n",
        "<h3 style=\"color: #e5c07b;\">Dil Modeli (LLM) Testi <font color=\"#98c379\">🚀</font></h3>\n",
        "<p>Sadece anahtarı yüklemek yeterli değildir. Her şeyin yolunda olduğundan emin olmak için, projemizde kullanacağımız <strong><code>gemini-2.5-flash</code></strong> modelini çağırarak küçük bir \"Merhaba!\" testi yapıyoruz. Bu test, hem API anahtarımızın geçerli olduğunu hem de seçtiğimiz modele erişimimiz olduğunu anında doğrular.</p>\n",
        "<blockquote style=\"border-left: 4px solid #c678dd; padding-left: 15px; margin: 10px 0; color: #abb2bf;\">\n",
        "💡 Bu hücrenin çıktısında ✅ <strong>'Her şey yolunda!'</strong> mesajını görmek, yapay zeka motorumuzun çalışmaya hazır olduğu ve projenin bir sonraki adımlarına geçebileceğimiz anlamına gelir.\n",
        "</blockquote>\n",
        "</div>"
      ],
      "metadata": {
        "id": "zCrbJF7vrDl1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "1pHG46ZsQFIB",
        "outputId": "b38e76c1-7bfd-4c54-a4fb-76eeb142d656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API anahtarı ayarlanıyor...\n",
            "✅ API anahtarı başarıyla yüklendi.\n",
            "Özel erişimli Gemini modeli ('gemini-2.5-flash') test ediliyor...\n",
            "✅ Gemini modeli başarıyla test edildi. Her şey yolunda!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "print(\"API anahtarı ayarlanıyor...\")\n",
        "\n",
        "try:\n",
        "    api_key = userdata.get('GOOGLE_API_KEY')\n",
        "    os.environ['GOOGLE_API_KEY'] = api_key\n",
        "    genai.configure(api_key=api_key)\n",
        "    print(\"✅ API anahtarı başarıyla yüklendi.\")\n",
        "\n",
        "    print(\"Özel erişimli Gemini modeli ('gemini-2.5-flash') test ediliyor...\")\n",
        "    model_test = genai.GenerativeModel('gemini-2.5-flash')\n",
        "    model_test.generate_content(\"Merhaba!\")\n",
        "    print(\"✅ Gemini modeli başarıyla test edildi. Her şey yolunda!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\"\"\n",
        "    ❌ HATA: Bir sorun oluştu.\n",
        "    Eğer '404 Not Found' hatası alıyorsan, bu Google hesabının bu modele erişimi olmayabilir.\n",
        "    Lütfen projeye ilk başladığın orijinal Google hesabını kullandığından emin ol.\n",
        "\n",
        "    Teknik Hata Detayı: {e}\n",
        "    \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGr_IqQRZ_74"
      },
      "source": [
        "<div style=\"background-color: #282c34; padding: 20px; border-radius: 10px; border: 1px solid #e5c07b;\">\n",
        "<h1 style=\"color: #e5c07b; font-size: 32px; text-align: center; border-bottom: 2px solid #e5c07b; padding-bottom: 10px; margin-top: 0;\">\n",
        "💾 Bölüm 2: Bilgi Bankasının İnşası (Tek Seferlik İşlem)\n",
        "</h1>\n",
        "<p style=\"font-size: 16px;\">Bu bölüm, projemizin en uzun süren adımlarını içerir. \"Nörobilim Asistanı\"nın \"hafızası\" burada sıfırdan inşa edilmiştir. Bu işlem yaklaşık 1.5 saat sürdüğü için, <strong>yalnızca bir kez çalıştırılmış</strong> ve sonuç Google Drive'a kaydedilmiştir.</p>\n",
        "<blockquote style=\"border-left: 4px solid #e06c75; padding-left: 15px; background-color: rgba(224, 108, 117, 0.1); color: #abb2bf;\">\n",
        "    ⚠️ <strong>DİKKAT:</strong> Aşağıdaki kod blokları bir <strong>\"kanıt\"</strong> niteliğindedir ve projeyi çalıştırırken <strong>ATLANMALIDIR.</strong>\n",
        "</blockquote>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_xWX3uHNTaS",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "print(\"--- ADIM 4: Metin Parçaları Vektörlere Dönüştürülüyor ---\")\n",
        "\n",
        "print(\"Embedding modeli (all-mpnet-base-v2) yükleniyor... Lütfen bekleyin.\")\n",
        "\n",
        "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "model_kwargs = {'device': 'cuda'}\n",
        "encode_kwargs = {'normalize_embeddings': True}\n",
        "\n",
        "try:\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=model_name,\n",
        "        model_kwargs=model_kwargs,\n",
        "        encode_kwargs=encode_kwargs\n",
        "    )\n",
        "    print(\"✅ Embedding modeli başarıyla yüklendi.\")\n",
        "\n",
        "    sample_chunk_content = chunks[0].page_content\n",
        "    vector = embeddings.embed_query(sample_chunk_content)\n",
        "\n",
        "    print(\"\\n--- Embedding Testi Başarılı ---\")\n",
        "    print(f\"Örnek metin parçası (ilk 80 karakter): '{sample_chunk_content[:80]}...'\")\n",
        "    print(f\"Oluşturulan vektörün boyutu (kaç sayıdan oluştuğu): {len(vector)}\")\n",
        "    print(f\"Vektörün ilk 5 değeri: {vector[:5]}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Hata: Embedding modeli yüklenemedi. Colab'de 'Runtime > Change runtime type' menüsünden GPU'nun (T4) seçili olduğundan emin olun. Hata detayı: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<h3 style=\"color: #e06c75;\">2.2. Geliştirme Sürecinde Hızlı Test ⚡</h3>\n",
        "<p>Nihai veritabanını oluşturma işlemi 1.5 saat gibi oldukça uzun bir süre aldığından, geliştirme döngüsünü hızlandırmak ve RAG akışının tüm adımlarını (Embedding -> Veritabanı Oluşturma -> Arama) hızlıca test edebilmek için stratejik bir ara adım uyguladık. Bu adımda, yaklaşık 300,000 parçalık tam veri setinden, sadece ilk <strong>10,000 parçayı</strong> alarak daha küçük ve yönetilebilir bir alt küme (subset) oluşturduk.</p>\n",
        "<p>Aşağıdaki kod blokları bu süreci göstermektedir:</p>\n",
        "<ol>\n",
        "<li><strong>Veri Küçültme:</strong> Tam <code>chunks</code> listesinden <code>[:10000]</code> dilimleme (slicing) yöntemiyle ilk 10,000 elemanı seçerek <code>test_chunks</code> adında yeni bir liste oluşturulur.</li>\n",
        "<li><strong>Test Veritabanı İnşası:</strong> <code>Chroma.from_documents</code> fonksiyonu bu sefer, bu küçük <code>test_chunks</code> listesiyle çağrılır. Bu işlem, tam veri setiyle saatler sürerken, bu alt küme ile sadece birkaç dakika içinde tamamlanır. Bu bize, <code>embedding</code> modelinin, <code>ChromaDB</code>'nin ve genel RAG mantığının doğru yapılandırıldığını hızlıca doğrulama imkanı tanımıştır.</li>\n",
        "</ol>\n",
        "<p>Bu \"hızlı prototipleme\" yaklaşımı, büyük ölçekli işlemi başlatmadan önce olası hataları erken bir aşamada tespit etmemizi sağlayarak projenin geliştirme sürecini önemli ölçüde verimli hale getirmiştir.</p>"
      ],
      "metadata": {
        "id": "bL1rZzJFEjIr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhvFGPkci2fO"
      },
      "outputs": [],
      "source": [
        "print(\"--- Hızlı Test İçin Veri Seti Küçültülüyor ---\")\n",
        "\n",
        "print(f\"Orijinal parça (chunk) sayısı: {len(chunks)}\")\n",
        "\n",
        "test_chunks = chunks[:10000]\n",
        "\n",
        "print(f\"Test için kullanılacak parça sayısı: {len(test_chunks)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylAZ1Qsxi7re"
      },
      "outputs": [],
      "source": [
        "print(\" Vektör Veritabanı (Hızlı Test) Oluşturuluyor ---\")\n",
        "\n",
        "from langchain_chroma import Chroma\n",
        "from tqdm import tqdm # ilerleme çubuğu için\n",
        "\n",
        "persist_directory = 'neuro_coach_db_test' # Test için farklı bir klasör adı\n",
        "\n",
        "try:\n",
        "    # Veritabanını oluştururken artık 'chunks' yerine 'test_chunks' kullanıyoruz!\n",
        "    vector_db_test = Chroma.from_documents(\n",
        "        documents=[test_chunks[0]],\n",
        "        embedding=embeddings,\n",
        "        persist_directory=persist_directory\n",
        "    )\n",
        "\n",
        "    remaining_chunks_test = test_chunks[1:]\n",
        "    batch_size = 100\n",
        "    for i in tqdm(range(0, len(remaining_chunks_test), batch_size), desc=\"Test chunk'ları ekleniyor\"):\n",
        "        batch = remaining_chunks_test[i:i+batch_size]\n",
        "        vector_db_test.add_documents(documents=batch)\n",
        "\n",
        "    print(f\"\\n✅ Test veritabanı başarıyla oluşturuldu.\")\n",
        "    print(f\"Test veritabanındaki vektör sayısı: {vector_db_test._collection.count()}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Hata: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 style=\"color: #98c379;\">2.3. Nihai Veritabanının Oluşturulması 🏗️</h3>\n",
        "<p>Hızlı testlerle tüm sistemin doğru çalıştığını doğruladıktan sonra, projenin en kritik ve en uzun süren adımı olan nihai bilgi bankasının inşasına geçtik. Bu adımda, <strong>tam veri setini (~300,000 parça)</strong> kullanarak, chatbot'umuzun \"beynini\" oluşturacak olan kalıcı vektör veritabanını inşa ediyoruz.</p>\n",
        "<p>Bu süreçte, bellek (RAM) taşması gibi sorunları önlemek ve süreci izlenebilir kılmak için verimli bir yöntem izlenmiştir:</p>\n",
        "<ol>\n",
        "<li><strong>Başlatma (Initialization):</strong> Veritabanı, <code>Chroma.from_documents</code> komutuyla sadece <strong>tek bir \"chunk\"</strong> kullanılarak başlatılır. Bu, veritabanı dosyalarının diskte ilk kez oluşturulmasını sağlar.</li>\n",
        "<li><strong>Toplu Ekleme (Batch Processing):</strong> Geri kalan yüz binlerce \"chunk\", <code>for</code> döngüsü içinde <strong>100'erli gruplar (batches)</strong> halinde veritabanına eklenir. <code>vector_db_final.add_documents()</code> metodu kullanılarak yapılan bu toplu ekleme işlemi, her bir \"chunk\"ı tek tek işlemekten çok daha verimlidir.</li>\n",
        "<li><strong>İzleme (Monitoring):</strong> Tüm bu döngü, <code>tqdm</code> kütüphanesi ile sarmalanmıştır. Bu, işlem sırasında bize canlı bir <strong>ilerleme çubuğu</strong> sunarak, sürecin ne kadarının tamamlandığını, ne kadar sürdüğünü ve tahmini olarak ne zaman biteceğini görmemizi sağlar.</li>\n",
        "</ol>\n",
        "<p>Bu \"toplu işleme\" ve \"izleme\" yaklaşımı, büyük veri setleriyle çalışırken hem sistem kaynaklarını verimli kullanmanın hem de uzun süren işlemleri kontrol altında tutmanın en iyi pratiklerinden biridir.</p>"
      ],
      "metadata": {
        "id": "l-bfM80YHb-y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RksFOWnek9ql"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "print(\"--- NİHAİ VERİTABANI OLUŞTURMA ---\")\n",
        "\n",
        "# Oluşturulacak klasörün adı\n",
        "persist_directory_final = 'neuro_coach_db_final'\n",
        "\n",
        "# Eğer klasör daha önce oluşturulduysa, işlemi atla\n",
        "if os.path.exists(persist_directory_final):\n",
        "    print(f\"'{persist_directory_final}' klasörü zaten mevcut. Oluşturma adımı atlanıyor.\")\n",
        "    # İstersen mevcut veritabanını yükleyebilirsin\n",
        "    # vector_db_final = Chroma(persist_directory=persist_directory_final, embedding_function=embeddings)\n",
        "else:\n",
        "    # İlk chunk ile veritabanını başlat\n",
        "    vector_db_final = Chroma.from_documents(\n",
        "        documents=[chunks[0]], # Orijinal 'chunks' listesini kullanıyoruz\n",
        "        embedding=embeddings,\n",
        "        persist_directory=persist_directory_final\n",
        "    )\n",
        "\n",
        "    # Geri kalan tüm chunk'ları ilerleme çubuğu ile ekle\n",
        "    remaining_chunks_final = chunks[1:]\n",
        "    batch_size = 100 # 100'erli gruplar halinde\n",
        "    for i in tqdm(range(0, len(remaining_chunks_final), batch_size), desc=\"Nihai chunk'lar ekleniyor\"):\n",
        "        batch = remaining_chunks_final[i:i+batch_size]\n",
        "        vector_db_final.add_documents(documents=batch)\n",
        "\n",
        "    print(f\"\\n✅ Nihai veritabanı başarıyla oluşturuldu.\")\n",
        "    print(f\"Veritabanındaki toplam vektör sayısı: {vector_db_final._collection.count()}\")\n",
        "\n",
        "print(\"\\nVeritabanı oluşturma işlemi tamamlandı.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 style=\"color: #56b6c2;\">2.4. Bilgi Bankasını Kalıcı Hale Getirme (Yedekleme) 💾</h3>\n",
        "<p>Yaklaşık 1.5 saat süren yoğun bir işlemle oluşturduğumuz vektör veritabanı, Colab'in geçici depolama alanında bulunmaktadır. Bu, Colab oturumu kapandığında bu değerli verinin kaybolacağı anlamına gelir. Bu uzun işlemi her seferinde tekrar yapmamak için, oluşturulan veritabanını kalıcı depolama alanımız olan <strong>Google Drive'a yedekliyoruz.</strong></p>\n",
        "<p>Bu süreç aşağıdaki adımları içerir:</p>\n",
        "<ol>\n",
        "<li><strong>Sıkıştırma:</strong> <code>ChromaDB</code> tarafından oluşturulan ve çok sayıda küçük dosyadan oluşan <code>neuro_coach_db_final</code> klasörü, taşıma işlemini hızlandırmak ve tek bir dosya haline getirmek için <code>!zip</code> komutuyla sıkıştırılarak bir <code>.zip</code> arşivi oluşturulur.</li>\n",
        "<li><strong>Google Drive Bağlantısı:</strong> <code>google.colab.drive</code> kütüphanesi kullanılarak Colab ortamı, kişisel Google Drive hesabımıza bağlanır.</li>\n",
        "<li><strong>Kopyalama:</strong> Oluşturulan <code>.zip</code> arşivi, <code>!cp</code> komutuyla Colab'in geçici diskinden, Google Drive'ımızdaki <code>NeuroCoach_Project</code> adlı özel bir klasörün içine kopyalanır.</li>\n",
        "</ol>\n",
        "<p>Bu yedekleme işlemi sayesinde, projenin sonraki tüm çalıştırmalarında bu uzun \"inşa\" sürecini atlayıp, doğrudan Google Drive'daki bu hazır veritabanını yükleyerek projemize dakikalar içinde başlayabiliriz.</p>"
      ],
      "metadata": {
        "id": "FyzMgpyvHylV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnFwTXM-4rtC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "print(\"--- Oluşturulan Veritabanını Google Drive'da Özel Bir Klasöre Kaydetme ---\")\n",
        "\n",
        "# --- AYARLAR ---\n",
        "drive_folder_name = \"NeuroCoach_Project\"\n",
        "persist_directory_final = 'neuro_coach_db_final'\n",
        "zip_filename = 'neuro_coach_db_final.zip'\n",
        "# --- BİTTİ ---\n",
        "\n",
        "drive_folder_path = f'/content/drive/MyDrive/{drive_folder_name}'\n",
        "drive_zip_path = f'{drive_folder_path}/{zip_filename}'\n",
        "colab_zip_path = f'/content/{zip_filename}'\n",
        "\n",
        "try:\n",
        "    # 1. Google Drive'ı bağla (İzin isteyecek)\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "    # 2. Drive'da hedef klasörü oluştur\n",
        "    if not os.path.exists(drive_folder_path):\n",
        "        print(f\"'{drive_folder_name}' klasörü Drive'da oluşturuluyor...\")\n",
        "        os.makedirs(drive_folder_path)\n",
        "    else:\n",
        "        print(f\"'{drive_folder_name}' klasörü Drive'da zaten mevcut.\")\n",
        "\n",
        "    # 3. Klasörü sıkıştır (bu işlem birkaç dakika sürebilir)\n",
        "    print(f\"'{persist_directory_final}' klasörü sıkıştırılıyor...\")\n",
        "    !zip -r {colab_zip_path} {persist_directory_final}\n",
        "\n",
        "    # 4. Sıkıştırılmış dosyayı Drive'a kopyala (bu işlem de birkaç dakika sürebilir)\n",
        "    print(f\"'{zip_filename}' dosyası hedef Drive klasörüne kopyalanıyor...\")\n",
        "    !cp {colab_zip_path} {drive_folder_path}/\n",
        "\n",
        "    print(f\"\\n✅ BAŞARILI! Veritabanınız şu konuma kaydedildi: '{drive_zip_path}'\")\n",
        "    print(\"Artık bu uzun işlemi bir daha yapmanıza gerek yok!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Kaydetme sırasında bir hata oluştu: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zhsaTTlbqX1"
      },
      "source": [
        "<div style=\"background-color: #282c34; padding: 20px; border-radius: 10px; border: 1px solid #56b6c2;\">\n",
        "<h1 style=\"color: #56b6c2; font-size: 32px; text-align: center; border-bottom: 2px solid #56b6c2; padding-bottom: 10px; margin-top: 0; text-shadow: 2px 2px 5px rgba(0,0,0,0.3);\">\n",
        "🚀 Bölüm 3: Hızlı Başlangıç - Hazır Bilgi Bankasını Yükleme\n",
        "</h1>\n",
        "<p style=\"font-size: 16px;\">Bölüm 2'de bir kez çalıştırıp Google Drive'a kaydettiğimiz o devasa emek ve zamanın meyvelerini bu bölümde topluyoruz. Bu bölüm, projeyi her başlattığımızda çalıştıracağımız \"hızlı başlangıç\" rutinidir. 1.5 saatlik veritabanı oluşturma sürecini atlayarak, projemizi birkaç dakika içinde kullanıma hazır hale getirir.</p>\n",
        "<h3 style=\"color: #e5c07b;\">Süreç Adımları <font color=\"#98c379\">⚙️</font></h3>\n",
        "<p>Aşağıdaki kod bloğu, bu hızlı başlangıç sürecini otomatize eder:</p>\n",
        "<ol>\n",
        "<li><strong>Akıllı Temizlik:</strong> Kod, başlamadan önce önceki çalıştırmalardan kalmış olabilecek eski veritabanı klasörlerini ve <code>.zip</code> dosyalarını otomatik olarak siler. Bu, olası dosya çakışmalarını önler.</li>\n",
        "<li><strong>Google Drive Bağlantısı:</strong> Projemizi, yedeklenmiş veritabanının bulunduğu Google Drive hesabımıza bağlar.</li>\n",
        "<li><strong>Veritabanını Getirme:</strong> Drive'daki sıkıştırılmış veritabanı (<code>.zip</code>) dosyasını Colab'in hızlı yerel diskine kopyalar ve arşivi açar.</li>\n",
        "<li><strong>Embedding Modelini Yükleme:</strong> Veritabanındaki vektörleri \"anlayabilmek\" için, o veritabanını oluştururken kullandığımız <strong>aynı</strong> <code>embedding</code> modelini tekrar hafızaya yükler. Bu, tutarlılık için kritik bir adımdır.</li>\n",
        "<li><strong>Veritabanını Aktif Etme:</strong> Son olarak, <code>Chroma</code>'ya diskteki klasörün yolunu göstererek, hazır bilgi bankasını <code>beyin</code> adında bir değişkene atar ve kullanıma hazır hale getirir.</li>\n",
        "</ol>\n",
        "<blockquote style=\"border-left: 4px solid #56b6c2; padding-left: 15px; margin: 10px 0; color: #abb2bf;\">\n",
        "</blockquote>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_jgPpitu7_w",
        "outputId": "af2da5ab-70b6-490e-cbf8-69a79ba87214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eskiden kalma veritabanı klasörü bulundu ve temizleniyor...\n",
            "Eskiden kalma .zip dosyası bulundu ve temizleniyor...\n",
            "Beynin düşünme şekli yükleniyor...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Beyin kullanıma hazırlanıyor...\n",
            "✅ Beyin başarıyla getirildi ve kullanıma hazır! İçinde 299942 adet bilgi parçacığı var.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# Kod, başlamadan önce eskiden kalma dosyaları kontrol edip silecek.\n",
        "if os.path.exists('/content/neuro_coach_db_final'):\n",
        "    print(\"Eskiden kalma veritabanı klasörü bulundu ve temizleniyor...\")\n",
        "    !rm -rf /content/neuro_coach_db_final\n",
        "\n",
        "if os.path.exists('/content/neuro_coach_db_final.zip'):\n",
        "    print(\"Eskiden kalma .zip dosyası bulundu ve temizleniyor...\")\n",
        "    !rm -f /content/neuro_coach_db_final.zip\n",
        "# --- TEMİZLİK BİTTİ ---\n",
        "\n",
        "# Beynin \"düşünme\" şeklini (embedding modelini) tekrar yükleyelim.\n",
        "print(\"Beynin düşünme şekli yükleniyor...\")\n",
        "embeddings_model = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
        "\n",
        ")\n",
        "\n",
        "# Şimdi Google Drive'a bağlanalım.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Beyin dosyasını (.zip) Drive'dan Colab'e kopyalayalım\n",
        "!cp /content/drive/MyDrive/NeuroCoach_Project/neuro_coach_db_final.zip /content/\n",
        "\n",
        "# Beyin dosyasını açalım (Artık soru sormayacak çünkü eski klasörü sildik)\n",
        "!unzip -q /content/neuro_coach_db_final.zip -d /content/\n",
        "\n",
        "# Son olarak, açtığımız beyin klasörünü kullanıma hazır hale getirelim\n",
        "print(\"Beyin kullanıma hazırlanıyor...\")\n",
        "beyin = Chroma(\n",
        "    persist_directory='neuro_coach_db_final',\n",
        "    embedding_function=embeddings_model\n",
        ")\n",
        "\n",
        "print(f\"✅ Beyin başarıyla getirildi ve kullanıma hazır! İçinde {beyin._collection.count()} adet bilgi parçacığı var.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #282c34; padding: 20px; border-radius: 10px; border: 1px solid #e06c75;\">\n",
        "<h1 style=\"color: #e06c75; font-size: 32px; text-align: center; border-bottom: 2px solid #e06c75; padding-bottom: 10px; margin-top: 0; text-shadow: 2px 2px 5px rgba(0,0,0,0.3);\">\n",
        "🌐 Bölüm 3.5: Çok Dilli Yeteneklerin Kazandırılması\n",
        "</h1>\n",
        "<p style=\"font-size: 16px;\">Bilgi bankamız İngilizce metinlerden oluştuğu için, RAG mimarisinin arama (Retrieval) adımının verimli çalışabilmesi adına kullanıcı sorgularının da İngilizce olması gerekmektedir. Bu bölümde, chatbot'umuzu evrensel hale getirmek ve farklı dillerdeki soruları anlayabilmesini sağlamak için iki temel yardımcı fonksiyon tanımlıyoruz. Bu fonksiyonlar, Gemini modelinin dil yeteneklerini akıllıca kullanarak bir \"evrensel tercüman\" görevi görür.</p>\n",
        "<h3 style=\"color: #e5c07b;\">Fonksiyonlar ve Görevleri <font color=\"#c678dd\">🛠️</font></h3>\n",
        "<ol>\n",
        "<li>\n",
        "<strong><code>detect_language(text)</code> - Dil Tespiti:</strong>\n",
        "<p>Bu fonksiyon, kullanıcıdan gelen metni alır ve Gemini modeline basit bir prompt (\"Bu metin hangi dilde?\") göndererek metnin dil kodunu (örn: 'tr', 'en') tespit eder. Bu, gereksiz çeviri işlemlerini önlemek için kritik bir ilk adımdır.</p>\n",
        "</li>\n",
        "<li>\n",
        "<strong><code>translate_to_english(text, source_language)</code> - İngilizce'ye Çeviri:</strong>\n",
        "<p>Eğer tespit edilen dil İngilizce değilse, bu fonksiyon devreye girer. Metni, Gemini modeline \"Bu metni İngilizce'ye çevir\" prompt'u ile göndererek, RAG sistemimizin arama yapabileceği standart bir formata dönüştürür. Metin zaten İngilizce ise, bu adımı atlayarak verimlilik sağlar.</p>\n",
        "</li>\n",
        "</ol>\n",
        "<blockquote style=\"border-left: 4px solid #e06c75; padding-left: 15px; margin: 10px 0; color: #abb2bf;\">\n",
        "💡 Bu yaklaşım, ayrı bir çeviri servisi API'sine ihtiyaç duymadan, zaten kullanmakta olduğumuz güçlü Gemini modelini hem dil tespiti hem de çeviri için kullanarak projemizi daha basit ve daha entegre bir yapıda tutmamızı sağlar.\n",
        "</blockquote>\n",
        "</div>"
      ],
      "metadata": {
        "id": "PLIs_trvJHL9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwXNWIvsw6cx",
        "outputId": "1e1d9204-61df-43ca-9722-eb56401a53f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Çeviri ve dil tespiti için yardımcı fonksiyonlar hazırlanıyor...\n",
            "✅ Yardımcı fonksiyonlar hazır.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "print(\"Çeviri ve dil tespiti için yardımcı fonksiyonlar hazırlanıyor...\")\n",
        "\n",
        "# Bu model, sadece bu hücredeki küçük işler için kullanılacak.\n",
        "helper_model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "def detect_language(text: str) -> str:\n",
        "    \"\"\"Verilen metnin dil kodunu ('en', 'tr' vb.) döndürür.\"\"\"\n",
        "    try:\n",
        "        prompt = f\"What language is this text? Answer with only the two-letter ISO 639-1 code. Text: '{text}'\"\n",
        "        response = helper_model.generate_content(prompt)\n",
        "        language_code = response.text.strip().lower()\n",
        "        print(f\"Tespit edilen dil: {language_code}\")\n",
        "        return language_code\n",
        "    except Exception as e:\n",
        "        print(f\"Dil tespiti sırasında hata: {e}\")\n",
        "        return \"en\" # Hata olursa, varsayılan olarak İngilizce kabul et\n",
        "\n",
        "def translate_to_english(text: str, source_language: str) -> str:\n",
        "    \"\"\"Verilen metni, kaynak dilini bilerek İngilizce'ye çevirir.\"\"\"\n",
        "    if \"en\" in source_language:\n",
        "        print(\"Metin zaten İngilizce, çeviri atlanıyor.\")\n",
        "        return text\n",
        "\n",
        "    try:\n",
        "        print(f\"'{source_language}' dilinden İngilizce'ye çevriliyor...\")\n",
        "        prompt = f\"Translate the following text to English. Respond with only the translated text: '{text}'\"\n",
        "        response = helper_model.generate_content(prompt)\n",
        "        translated_text = response.text.strip()\n",
        "        print(f\"Çeviri: {translated_text}\")\n",
        "        return translated_text\n",
        "    except Exception as e:\n",
        "        print(f\"Çeviri sırasında hata: {e}\")\n",
        "        return text\n",
        "\n",
        "print(\"✅ Yardımcı fonksiyonlar hazır.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #282c34; padding: 20px; border-radius: 10px; border: 1px solid #98c379;\">\n",
        "<h1 style=\"color: #98c379; font-size: 32px; text-align: center; border-bottom: 2px solid #98c379; padding-bottom: 10px; margin-top: 0; text-shadow: 2px 2px 5px rgba(0,0,0,0.3);\">\n",
        "⚙️ Bölüm 4: Ana Chatbot Motorunun İnşası\n",
        "</h1>\n",
        "<p style=\"font-size: 16px;\">Bu bölümde, projemizin kalbini ve beynini oluşturan ana RAG (Retrieval Augmented Generation) motorunu inşa ediyoruz. Bu motor, hem önceki konuşmaları hatırlayabilen (hafızalı) hem de farklı dillerde talimat alabilen (çok dilli) gelişmiş bir yapıya sahiptir. Bu adımların sonunda, Gradio arayüzüne bağlanmaya hazır, tam işlevsel bir chatbot mantığımız olacak.</p>\n",
        "<h3 style=\"color: #e5c07b;\">4.1. Temel Bileşenlerin Hazırlanması <font color=\"#61afef\">🧩</font></h3>\n",
        "<p>Zincirimizi oluşturmadan önce, onu oluşturan ana parçaları hazırlıyoruz:</p>\n",
        "<ul>\n",
        "<li><strong>Retriever (Arama Yapıcı):</strong> Bir önceki bölümde yüklediğimiz <code>beyin</code> (ChromaDB veritabanı) değişkenini, LangChain'in anlayacağı bir \"arama motoruna\" dönüştürüyoruz. Her sorguda en alakalı 5 belgeyi getirecek şekilde ayarlanmıştır.</li>\n",
        "<li><strong>LLM (Dil Modeli):</strong> Cevapları üretecek olan <code>gemini-2.5-flash</code> modelini LangChain ile uyumlu hale getiriyoruz.</li>\n",
        "<li><strong>Memory (Hafıza):</strong> <code>ConversationBufferMemory</code> ile chatbot'umuzun sohbet geçmişini saklayacağı geçici bir hafıza alanı oluşturuyoruz.</li>\n",
        "</ul>\n",
        "<br>\n",
        "<h3 style=\"color: #e5c07b;\">4.2. Çok Dilli Prompt Şablonları <font color=\"#c678dd\">🌍</font></h3>\n",
        "<p>Chatbot'umuzun, kullanıcının sorduğu dile göre cevap verebilmesi için iki ayrı \"görev tanımı\" (prompt şablonu) hazırlıyoruz. Bir tanesi Türkçe cevap üretmesi için talimatlar içerirken, diğeri İngilizce cevap üretmesi için talimatlar içerir. Bu şablonlar, bir sonraki bölümde (Gradio) kullanıcının diline göre dinamik olarak seçilip zincire enjekte edilecektir.</p>\n",
        "<br>\n",
        "<h3 style=\"color: #e5c07b;\">4.3. Hafızalı Ana Zincirin Oluşturulması <font color=\"#98c379\">🔗</font></h3>\n",
        "<p>Tüm parçaları, LangChain'in güçlü ve hazır zincirlerinden biri olan <code>ConversationalRetrievalChain</code> ile birleştiriyoruz. Bu zincir, bizim için birçok karmaşık işi otomatik olarak yapar:</p>\n",
        "<ol>\n",
        "<li>Yeni soruyu ve <strong>hafızadaki eski konuşmaları</strong> birleştirerek daha akıllı bir arama sorgusu oluşturur.</li>\n",
        "<li>Bu sorguyla <strong>Retriever</strong>'ı kullanarak veritabanında arama yapar.</li>\n",
        "<li>Bulunan belgeleri, sohbet geçmişini ve yeni soruyu <strong>LLM</strong>'e göndererek nihai cevabı üretir.</li>\n",
        "<li>Yeni soru ve cevabı otomatik olarak <strong>hafızaya</strong> ekler.</li>\n",
        "<li><code>return_source_documents=True</code> parametresi sayesinde, cevabı üretirken kullandığı kaynak belgeleri de bize sunar.</li>\n",
        "</ol>\n",
        "<blockquote style=\"border-left: 4px solid #98c379; padding-left: 15px; margin: 10px 0; color: #abb2bf;\">\n",
        "💡 Bu \"hazır zincir\" yaklaşımı, karmaşık LCEL yapıları kurmadan, hafıza yönetimini ve RAG akışını son derece basit ve okunabilir bir kodla uygulamamızı sağlar.\n",
        "</blockquote>\n",
        "</div>"
      ],
      "metadata": {
        "id": "ffm5gJj6JjY7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eP_TIlj6vuzF",
        "outputId": "ccd7f79c-3418-4c2c-977c-050992cd0146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hafızalı temel motor ve çok dilli prompt'lar hazırlanıyor...\n",
            "✅ Kaynak gösterebilen, hafızalı temel motor başarıyla oluşturuldu.\n",
            "\n",
            "--- Test Aşaması ---\n",
            "CEVAP: Erteleme (procrastination), önemli görevleri isteyerek erteleyip, daha az önemli veya keyifli aktivitelere yönelme eylemidir.\n",
            "\n",
            "Metne göre erteleme:\n",
            "*   Dikkatimizi gerektiren görevleri geciktirme veya erteleme eylemidir.\n",
            "*   Daha fazla öneme veya aciliyete sahip bir göreve yönelmek yerine, daha az önemli veya keyifli bir şeyi yapmayı gönüllü olarak seçme davranışıdır.\n",
            "*   Motivasyon eksikliği, kötü zaman yönetimi becerileri, başarısızlık veya başarı korkusu gibi faktörlerden kaynaklanabilir.\n",
            "*   Popüler inanışın aksine, zaman yönetimi veya tembellikle ilgili olmayıp, gelecekteki olaylar hakkında kötü duygusal düzenlemeyle ilgilidir.\n",
            "KAYNAK SAYISI: 5\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "print(\"Hafızalı temel motor ve çok dilli prompt'lar hazırlanıyor...\")\n",
        "\n",
        "# 1. Temel Bileşenler\n",
        "arama_yapici = beyin.as_retriever(search_kwargs={\"k\": 5})\n",
        "llm_for_chain = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)\n",
        "\n",
        "# 2. Hafıza Nesnesi\n",
        "memory = ConversationBufferMemory(\n",
        "    memory_key='chat_history',\n",
        "    return_messages=True,\n",
        "    output_key='answer'\n",
        ")\n",
        "\n",
        "# 3. FARKLI DİLLER İÇİN PROMPT ŞABLONLARI\n",
        "# Bu prompt'lar, zincirin içine sonradan enjekte edilecek.\n",
        "prompt_tr_template = \"\"\"Sen 'Nörobilim asistanısın. Konuşma geçmişini ({chat_history}) dikkate alarak, sana verilen yeni bilgileri ({context}) kullanarak kullanıcının yeni sorusuna ({question}) TÜRKÇE cevap ver. Cevabın yardımsever ve anlaşılır olsun.\"\"\"\n",
        "prompt_en_template = \"\"\"You are 'Neuroscience assistant'. Considering the chat history ({chat_history}), answer the user's new question ({question}) in ENGLISH, using the new context ({context}). Be helpful and clear.\"\"\"\n",
        "\n",
        "prompt_tr = PromptTemplate.from_template(prompt_tr_template)\n",
        "prompt_en = PromptTemplate.from_template(prompt_en_template)\n",
        "\n",
        "\n",
        "# 4. TEMEL Hafızalı Zincir\n",
        "conversational_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm=llm_for_chain,\n",
        "    retriever=arama_yapici,\n",
        "    memory=memory,\n",
        "    output_key='answer',\n",
        "    return_source_documents=True\n",
        "    # -------------------------\n",
        ")\n",
        "\n",
        "print(\"✅ Kaynak gösterebilen, hafızalı temel motor başarıyla oluşturuldu.\")\n",
        "\n",
        "print(\"\\n--- Test Aşaması ---\")\n",
        "soru1 = \"Erteleme (procrastination) nedir?\"\n",
        "result = conversational_chain.invoke({\"question\": soru1})\n",
        "\n",
        "print(\"CEVAP:\", result['answer'])\n",
        "print(\"KAYNAK SAYISI:\", len(result['source_documents']))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #282828; padding: 20px; border-radius: 10px; border: 1px solid #d3869b;\">\n",
        "<h1 style=\"color: #d3869b; font-size: 32px; text-align: center; border-bottom: 2px solid #d3869b; padding-bottom: 10px; margin-top: 0; text-shadow: 2px 2px 5px rgba(0,0,0,0.3);\">\n",
        "🎨 Bölüm 5: İnteraktif Web Arayüzü (Gradio)\n",
        "</h1>\n",
        "<p style=\"font-size: 16px;\">Projemizin son adımında, önceki bölümlerde inşa ettiğimiz güçlü ve akıllı chatbot motorunu, kullanıcıların kolayca etkileşime girebileceği modern ve şık bir web arayüzü ile buluşturuyoruz. Bu, projemizin teknik yeteneklerini son kullanıcıya sunan en önemli vitrinidir.</p>\n",
        "<h3 style=\"color: #83a598;\">5.1. Arayüz Tasarımı ve Felsefesi ✨</h3>\n",
        "<p>Arayüzün tasarımında, projenin \"nörobilim\" ve \"teknoloji\" temalarını yansıtan, fütüristik ve kullanıcı dostu bir yaklaşım benimsenmiştir:</p>\n",
        "<ul>\n",
        "<li><strong>Özel Tasarım (CSS):</strong> Arayüz, standart Gradio görünümünün dışına çıkarak, özel CSS kodları ile tamamen kişiselleştirilmiştir. Kozmik temalı bir arkaplan resmi, \"buzlu cam\" efekti veren yarı şeffaf ana panel ve markalaşma için özel logo ve font kullanımı gibi modern web tasarım teknikleri uygulanmıştır.</li>\n",
        "<li><strong>Bileşen Yerleşimi (<code>gr.Blocks</code>):</strong> Standart <code>ChatInterface</code> yerine, arayüz bileşenleri (logo, başlık, sohbet penceresi, metin kutusu) üzerinde tam kontrol sağlayan <code>gr.Blocks</code> yapısı kullanılmıştır. Bu sayede, logo ve başlık yan yana hizalanarak profesyonel bir görünüm elde edilmiştir.</li>\n",
        "</ul>\n",
        "<br>\n",
        "<h3 style=\"color: #83a598;\">5.2. Arayüz Mantığı ve Çalışma Akışı 🧠</h3>\n",
        "<p>Görsel tasarımın arkasında, önceki bölümlerde oluşturduğumuz tüm RAG mantığını yöneten akıllı bir fonksiyon yatmaktadır:</p>\n",
        "<ol>\n",
        "<li><strong><code>get_neuro_coach_response()</code> Fonksiyonu:</strong> Bu \"ana beyin\" fonksiyonu, Gradio arayüzünden gelen her bir kullanıcı mesajını alır.</li>\n",
        "<li><strong>Çok Dilli İşlem:</strong> Fonksiyon, Bölüm 3.5'teki yardımcı fonksiyonları çağırarak mesajın dilini tespit eder ve gerekirse İngilizce'ye çevirir.</li>\n",
        "<li><strong>Dinamik Prompting:</strong> Bölüm 4'te hazırlanan, dile özel prompt şablonlarından uygun olanı seçer ve hafızalı ana zincirin (<code>conversational_chain</code>) görev tanımını o anki konuşmanın diline göre günceller.</li>\n",
        "<li><strong>Cevap Üretimi:</strong> Güncellenmiş zinciri çalıştırarak nihai, hem hafızalı hem de doğru dilde cevabı üretir ve arayüze geri döndürür.</li>\n",
        "</ol>\n",
        "<blockquote style=\"border-left: 4px solid #d3869b; padding-left: 15px; margin: 10px 0; color: #d4be98;\">\n",
        "🚀 <strong>Sonuç:</strong> Bu hücre çalıştırıldığında, herkesle paylaşılabilen bir \"Public URL\" oluşturulur. Bu link üzerinden erişilen arayüz, projemizin tüm yeteneklerini (hafıza, çok dillilik, RAG) son kullanıcıya sunan, tam işlevsel bir web uygulamasıdır.\n",
        "</blockquote>\n",
        "</div>"
      ],
      "metadata": {
        "id": "63MC9MGaKE06"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxoj5_G9Lsje"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import time\n",
        "import re\n",
        "\n",
        "print(\"Projenin nihai arayüzü inşa ediliyor...\")\n",
        "\n",
        "# --- GÖRSEL TASARIM (CSS ve URL'ler) ---\n",
        "LOGO_URL = \"https://github.com/Fatmanurkntr/Neuroscience-Chatbot/blob/main/chatbotlogo1.png?raw=true\"\n",
        "BACKGROUND_IMAGE_URL = \"https://github.com/Fatmanurkntr/Neuroscience-Chatbot/blob/main/neuro.jpg?raw=true\"\n",
        "\n",
        "# Tüm görsel ayarları içeren CSS kodu.\n",
        "custom_css = f\"\"\"\n",
        "@import url('https://fonts.googleapis.com/css2?family=Poppins:wght@400;600;700&display=swap');\n",
        "\n",
        "body, .gradio-container {{\n",
        "    font-family: 'Poppins', sans-serif;\n",
        "    background-image: url('{BACKGROUND_IMAGE_URL}');\n",
        "    background-size: cover;\n",
        "    background-position: center;\n",
        "    background-attachment: fixed;\n",
        "}}\n",
        "\n",
        "#app_container {{\n",
        "    max-width: 800px;\n",
        "    margin: 40px auto;\n",
        "    background-color: rgba(20, 30, 48, 0.75);\n",
        "    backdrop-filter: blur(15px);\n",
        "    border-radius: 20px;\n",
        "    padding: 30px;\n",
        "    border: 1px solid rgba(255, 255, 255, 0.1);\n",
        "}}\n",
        "\n",
        "/* Başlığı saran ana konteyner için Flexbox ayarları */\n",
        "#header_container {{\n",
        "    display: flex !important;\n",
        "    flex-direction: row !important;\n",
        "    justify-content: center !important;\n",
        "    align-items: center !important;\n",
        "    margin-bottom: 25px !important;\n",
        "    gap: 20px !important;\n",
        "}}\n",
        "\n",
        "/* Logo'nun kendisi için boyut ayarı */\n",
        "#header_logo img {{\n",
        "    width: 80px !important;\n",
        "    height: 80px !important;\n",
        "    min-width: 80px !important;\n",
        "}}\n",
        "\n",
        "/* Metinleri saran grup için ayarlar */\n",
        "#header_text_group {{\n",
        "    display: flex !important;\n",
        "    flex-direction: column !important;\n",
        "    align-items: flex-start !important;\n",
        "}}\n",
        "\n",
        "/* Ana Başlık ve Alt Başlık stilleri */\n",
        "#header_title {{ color: #FFFFFF; font-size: 32px; font-weight: 700; margin: 0; padding: 0; line-height: 1.2; }}\n",
        "#header_subtitle {{ color: #D1D5DB; font-size: 16px; margin-top: 5px; padding: 0; }}\n",
        "\n",
        "/* Sohbet baloncukları ve diğer stiller */\n",
        "#main_chatbot .user {{ background: linear-gradient(to right, rgba(79, 70, 229, 0.8), rgba(124, 58, 237, 0.8)) !important; }}\n",
        "#main_chatbot .bot {{ background-color: rgba(55, 65, 81, 0.8) !important; }}\n",
        "\"\"\"\n",
        "\n",
        "# --- ANA MANTIK FONKSİYONU (Gradio için özel) ---\n",
        "def get_neuro_coach_response(message: str, history: list):\n",
        "    \"\"\"\n",
        "    Bu \"ana beyin\" fonksiyonu, Gradio'dan gelen her soru için tüm RAG sürecini yönetir.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"--- Arayüzden Gelen Soru: {message} ---\")\n",
        "\n",
        "    try:\n",
        "        language = detect_language(message)\n",
        "        english_question = translate_to_english(message, language)\n",
        "\n",
        "        if language == \"tr\":\n",
        "            selected_prompt = prompt_tr\n",
        "        else:\n",
        "            selected_prompt = prompt_en\n",
        "\n",
        "        conversational_chain.combine_docs_chain.llm_chain.prompt = selected_prompt\n",
        "\n",
        "        result = conversational_chain.invoke({\"question\": english_question})\n",
        "        answer = result.get('answer', \"Üzgünüm, bir cevap üretemedim.\")\n",
        "\n",
        "        print(f\"--- Üretilen Cevap ---\")\n",
        "        return answer\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"!!!!!! HATA OLUŞTU: {e} !!!!!!\")\n",
        "        return f\"Üzgünüm, bir hata oluştu: {e}\"\n",
        "\n",
        "# --- 3. ARAYÜZÜN İNŞASI VE CANLANDIRILMASI ---\n",
        "with gr.Blocks(css=custom_css, theme=None, title=\"Nörobilim Asistanı\") as demo:\n",
        "\n",
        "    with gr.Column(elem_id=\"app_container\"):\n",
        "\n",
        "        # Başlık Bölümü\n",
        "        with gr.Row(elem_id=\"header_container\"):\n",
        "            gr.Image(value=LOGO_URL, elem_id=\"header_logo\", show_download_button=False, container=False, show_fullscreen_button=False, scale=0)\n",
        "            with gr.Column(elem_id=\"header_text_group\", scale=1):\n",
        "                gr.Markdown(\"# Nörobilim Asistanı\", elem_id=\"header_title\")\n",
        "                gr.Markdown(\"Zihninizin karmaşık haritasını keşfedin. Motivasyon, erteleme ve alışkanlıklarınızın ardındaki nörobilimsel sırları aydınlatmak için bir soru sorun.\", elem_id=\"header_subtitle\")\n",
        "\n",
        "        # 1. Sohbet penceresi\n",
        "        chatbot = gr.Chatbot(height=450, render_markdown=True, elem_id=\"main_chatbot\", label=\"Sohbet\")\n",
        "\n",
        "        # 2. Mesaj yazma kutusu\n",
        "        msg = gr.Textbox(placeholder=\"Örn: 'Erteleme alışkanlığından nasıl kurtulurum?'\", show_label=False)\n",
        "\n",
        "        # 3. Örnekler\n",
        "        gr.Examples(\n",
        "            [\"Erteleme nedir?\", \"Peki bununla nasıl başa çıkabilirim?\", \"How to build a new habit?\"],\n",
        "            inputs=msg,\n",
        "            label=\"Denemek için bir soru seçin:\"\n",
        "        )\n",
        "\n",
        "        # Arayüz Mantığı\n",
        "        def user(user_message, history):\n",
        "            return \"\", history + [[user_message, None]]\n",
        "\n",
        "        def bot(history):\n",
        "            user_message = history[-1][0]\n",
        "            bot_message = get_neuro_coach_response(user_message, history[:-1])\n",
        "            history[-1][1] = bot_message\n",
        "            return history\n",
        "\n",
        "        msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
        "            bot, chatbot, chatbot\n",
        "        )\n",
        "\n",
        "# Arayüzü Başlatma\n",
        "print(\"Arayüz başlatılıyor...\")\n",
        "demo.launch(share=True, debug=True)\n",
        "\n",
        "# Kapanmayı Önleme\n",
        "print(\"Gradio sunucusu aktif. Bu hücreyi canlı tutmak için çalışmaya devam edecek.\")\n",
        "while True:\n",
        "    time.sleep(1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}