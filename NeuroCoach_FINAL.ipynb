{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #282c34; padding: 20px; border-radius: 10px; border: 1px solid #61afef;\">\n",
        "<!-- BAÅLIÄI BÃœYÃœTMEK Ä°Ã‡Ä°N font-size DEÄERÄ°NÄ° ARTIRDIK -->\n",
        "<h1 style=\"color: #61afef; font-size: 32px; text-align: center; border-bottom: 2px solid #61afef; padding-bottom: 10px; margin-top: 0; text-shadow: 2px 2px 5px rgba(0,0,0,0.3);\">\n",
        "ğŸ§  BÃ¶lÃ¼m 1: Proje OrtamÄ±nÄ±n Kurulumu\n",
        "</h1>\n",
        "<p style=\"font-size: 16px;\">Bu bÃ¶lÃ¼mde, <strong>NÃ¶robilim AsistanÄ±</strong> projemizin Ã§alÄ±ÅŸmasÄ± iÃ§in gerekli olan tÃ¼m temel altyapÄ±yÄ± hazÄ±rlayacaÄŸÄ±z. SÃ¼reÃ§, projemizin saÄŸlam bir temel Ã¼zerine inÅŸa edilmesini saÄŸlayan iki kritik adÄ±mdan oluÅŸur.</p>\n",
        "<h3 style=\"color: #e5c07b;\">1.1. Gerekli KÃ¼tÃ¼phanelerin YÃ¼klenmesi <font color=\"#98c379\">ğŸ“š</font></h3>\n",
        "<p>Projemizin bel kemiÄŸini oluÅŸturan Python kÃ¼tÃ¼phanelerini Colab ortamÄ±na kuruyoruz. Bu adÄ±mda, tÃ¼m bileÅŸenlerin birbiriyle uyumlu Ã§alÄ±ÅŸmasÄ±nÄ± garantileyen belirli versiyonlar ve kurulum yÃ¶ntemleri kullanÄ±yoruz.</p>\n",
        "<ul>\n",
        "<li><font color=\"#61afef\"><strong>LangChain & Ekosistemi:</strong></font> RAG mimarisini ve chatbot'un ana mantÄ±ÄŸÄ±nÄ± (zincirler, hafÄ±za vb.) oluÅŸturmak iÃ§in.</li>\n",
        "<li><font color=\"#c678dd\"><strong>Google Generative AI:</strong></font> Projemizin \"dÃ¼ÅŸÃ¼nen beyni\" olan gÃ¼Ã§lÃ¼ <code>Gemini</code> dil modelini kullanabilmek iÃ§in.</li>\n",
        "<li><font color=\"#e5c07b\"><strong>VektÃ¶r VeritabanÄ±:</strong></font> <code>ChromaDB</code> ve ilgili <code>LangChain</code> entegrasyonlarÄ±, bilgi bankamÄ±zÄ± verimli bir ÅŸekilde saklamak ve iÃ§inde anlamsal arama yapmak iÃ§in.</li>\n",
        "<li><font color=\"#e06c75\"><strong>Hugging Face:</strong></font> Metinleri matematiksel olarak anlaÅŸÄ±labilir vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼ren <code>embedding</code> modelini Ã§ekmek iÃ§in.</li>\n",
        "</ul>\n",
        "<br>\n",
        "<h3 style=\"color: #e5c07b;\">1.2. Kurulum DoÄŸrulamasÄ± <font color=\"#98c379\">âœ…</font></h3>\n",
        "<p>Kurulum tamamlandÄ±ktan sonra, yÃ¼klenen tÃ¼m kÃ¼tÃ¼phanelerin Python tarafÄ±ndan doÄŸru bir ÅŸekilde tanÄ±nÄ±p tanÄ±nmadÄ±ÄŸÄ±nÄ± bir <code>import</code> testi ile kontrol ediyoruz.</p>\n",
        "<blockquote style=\"border-left: 4px solid #56b6c2; padding-left: 15px; margin: 10px 0; color: #abb2bf;\">\n",
        "ğŸš€ Bu testin baÅŸarÄ±yla geÃ§mesi, geliÅŸtirme ortamÄ±mÄ±zÄ±n <strong>saÄŸlÄ±klÄ±</strong> ve projenin geri kalanÄ±na baÅŸlamak iÃ§in <strong>hazÄ±r</strong> olduÄŸunu doÄŸrular.\n",
        "</blockquote>\n",
        "</div>"
      ],
      "metadata": {
        "id": "VUwnvUYaWYJG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1Zv5eikaMLd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b67bde62-388a-43f3-f4e0-cf36affbc656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ADIM 1: Gerekli modern kÃ¼tÃ¼phaneler yÃ¼kleniyor... ---\n",
            "âœ… Kurulum tamamlandÄ± ve Colab ile uyumlu hale getirildi.\n",
            "\n",
            "--- ADIM 2: GÃ¼ncel import testi ---\n",
            "âœ… TÃ¼m import'lar baÅŸarÄ±yla yÃ¼klendi! Ortam temiz ve uyumlu ğŸš€\n"
          ]
        }
      ],
      "source": [
        "print(\"--- ADIM 1: Gerekli modern kÃ¼tÃ¼phaneler yÃ¼kleniyor... ---\")\n",
        "!pip install -U -q \\\n",
        "    langchain \\\n",
        "    langchain-core \\\n",
        "    langchain-community \\\n",
        "    langchain-chroma \\\n",
        "    langchain-huggingface \\\n",
        "    langchain-text-splitters \\\n",
        "    langchain-google-genai \\\n",
        "    chromadb \\\n",
        "    datasets \\\n",
        "    google-generativeai==0.8.5 \\\n",
        "    pandas==2.2.2 \\\n",
        "    requests==2.32.4 \\\n",
        "    gradio\n",
        "\n",
        "print(\"âœ… Kurulum tamamlandÄ± ve Colab ile uyumlu hale getirildi.\")\n",
        "\n",
        "print(\"\\n--- ADIM 2: GÃ¼ncel import testi ---\")\n",
        "try:\n",
        "    import os, time, gradio as gr, pandas as pd, google.generativeai as genai\n",
        "    from datasets import load_dataset\n",
        "    from langchain_chroma import Chroma\n",
        "    from langchain_huggingface import HuggingFaceEmbeddings\n",
        "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "    from langchain.memory import ConversationBufferMemory\n",
        "    from langchain.prompts import ChatPromptTemplate\n",
        "    from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "    from langchain.chains import create_retrieval_chain\n",
        "    print(\"âœ… TÃ¼m import'lar baÅŸarÄ±yla yÃ¼klendi! Ortam temiz ve uyumlu ğŸš€\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Import hatasÄ±: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #282c34; padding: 20px; border-radius: 10px; border: 1px solid #c678dd;\">\n",
        "<h1 style=\"color: #c678dd; font-size: 32px; text-align: center; border-bottom: 2px solid #c678dd; padding-bottom: 10px; margin-top: 0; text-shadow: 2px 2px 5px rgba(0,0,0,0.3);\">\n",
        "ğŸ”‘ BÃ¶lÃ¼m 1.2: API YapÄ±landÄ±rmasÄ± ve Model Testi\n",
        "</h1>\n",
        "<p style=\"font-size: 16px;\">KÃ¼tÃ¼phaneleri kurduktan sonraki bu kritik adÄ±mda, projemize Google'Ä±n gÃ¼Ã§lÃ¼ yapay zeka modellerini kullanma yetkisi veriyoruz.</p>\n",
        "<h3 style=\"color: #e5c07b;\">API AnahtarÄ± YapÄ±landÄ±rmasÄ± <font color=\"#e06c75\">ğŸ”</font></h3>\n",
        "<p>API anahtarÄ±mÄ±zÄ± doÄŸrudan kodun iÃ§ine yazmak yerine, Colab'in gÃ¼venli <code>Secrets</code> (Gizli Anahtarlar) Ã¶zelliÄŸini kullanarak <code>GOOGLE_API_KEY</code> adÄ±yla sakladÄ±ÄŸÄ±mÄ±z anahtarÄ± Ã§ekiyoruz. Bu yÃ¶ntem, anahtarÄ±mÄ±zÄ±n gizli ve gÃ¼vende kalmasÄ±nÄ± saÄŸlar. <code>genai.configure()</code> fonksiyonu ile bu anahtarÄ± kullanarak Google servisleriyle gÃ¼venli bir baÄŸlantÄ± kuruyoruz.</p>\n",
        "<br>\n",
        "<h3 style=\"color: #e5c07b;\">Dil Modeli (LLM) Testi <font color=\"#98c379\">ğŸš€</font></h3>\n",
        "<p>Sadece anahtarÄ± yÃ¼klemek yeterli deÄŸildir. Her ÅŸeyin yolunda olduÄŸundan emin olmak iÃ§in, projemizde kullanacaÄŸÄ±mÄ±z <strong><code>gemini-2.5-flash</code></strong> modelini Ã§aÄŸÄ±rarak kÃ¼Ã§Ã¼k bir \"Merhaba!\" testi yapÄ±yoruz. Bu test, hem API anahtarÄ±mÄ±zÄ±n geÃ§erli olduÄŸunu hem de seÃ§tiÄŸimiz modele eriÅŸimimiz olduÄŸunu anÄ±nda doÄŸrular.</p>\n",
        "<blockquote style=\"border-left: 4px solid #c678dd; padding-left: 15px; margin: 10px 0; color: #abb2bf;\">\n",
        "ğŸ’¡ Bu hÃ¼crenin Ã§Ä±ktÄ±sÄ±nda âœ… <strong>'Her ÅŸey yolunda!'</strong> mesajÄ±nÄ± gÃ¶rmek, yapay zeka motorumuzun Ã§alÄ±ÅŸmaya hazÄ±r olduÄŸu ve projenin bir sonraki adÄ±mlarÄ±na geÃ§ebileceÄŸimiz anlamÄ±na gelir.\n",
        "</blockquote>\n",
        "</div>"
      ],
      "metadata": {
        "id": "zCrbJF7vrDl1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "1pHG46ZsQFIB",
        "outputId": "b38e76c1-7bfd-4c54-a4fb-76eeb142d656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API anahtarÄ± ayarlanÄ±yor...\n",
            "âœ… API anahtarÄ± baÅŸarÄ±yla yÃ¼klendi.\n",
            "Ã–zel eriÅŸimli Gemini modeli ('gemini-2.5-flash') test ediliyor...\n",
            "âœ… Gemini modeli baÅŸarÄ±yla test edildi. Her ÅŸey yolunda!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "print(\"API anahtarÄ± ayarlanÄ±yor...\")\n",
        "\n",
        "try:\n",
        "    api_key = userdata.get('GOOGLE_API_KEY')\n",
        "    os.environ['GOOGLE_API_KEY'] = api_key\n",
        "    genai.configure(api_key=api_key)\n",
        "    print(\"âœ… API anahtarÄ± baÅŸarÄ±yla yÃ¼klendi.\")\n",
        "\n",
        "    print(\"Ã–zel eriÅŸimli Gemini modeli ('gemini-2.5-flash') test ediliyor...\")\n",
        "    model_test = genai.GenerativeModel('gemini-2.5-flash')\n",
        "    model_test.generate_content(\"Merhaba!\")\n",
        "    print(\"âœ… Gemini modeli baÅŸarÄ±yla test edildi. Her ÅŸey yolunda!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\"\"\n",
        "    âŒ HATA: Bir sorun oluÅŸtu.\n",
        "    EÄŸer '404 Not Found' hatasÄ± alÄ±yorsan, bu Google hesabÄ±nÄ±n bu modele eriÅŸimi olmayabilir.\n",
        "    LÃ¼tfen projeye ilk baÅŸladÄ±ÄŸÄ±n orijinal Google hesabÄ±nÄ± kullandÄ±ÄŸÄ±ndan emin ol.\n",
        "\n",
        "    Teknik Hata DetayÄ±: {e}\n",
        "    \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGr_IqQRZ_74"
      },
      "source": [
        "<div style=\"background-color: #282c34; padding: 20px; border-radius: 10px; border: 1px solid #e5c07b;\">\n",
        "<h1 style=\"color: #e5c07b; font-size: 32px; text-align: center; border-bottom: 2px solid #e5c07b; padding-bottom: 10px; margin-top: 0;\">\n",
        "ğŸ’¾ BÃ¶lÃ¼m 2: Bilgi BankasÄ±nÄ±n Ä°nÅŸasÄ± (Tek Seferlik Ä°ÅŸlem)\n",
        "</h1>\n",
        "<p style=\"font-size: 16px;\">Bu bÃ¶lÃ¼m, projemizin en uzun sÃ¼ren adÄ±mlarÄ±nÄ± iÃ§erir. \"NÃ¶robilim AsistanÄ±\"nÄ±n \"hafÄ±zasÄ±\" burada sÄ±fÄ±rdan inÅŸa edilmiÅŸtir. Bu iÅŸlem yaklaÅŸÄ±k 1.5 saat sÃ¼rdÃ¼ÄŸÃ¼ iÃ§in, <strong>yalnÄ±zca bir kez Ã§alÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ</strong> ve sonuÃ§ Google Drive'a kaydedilmiÅŸtir.</p>\n",
        "<blockquote style=\"border-left: 4px solid #e06c75; padding-left: 15px; background-color: rgba(224, 108, 117, 0.1); color: #abb2bf;\">\n",
        "    âš ï¸ <strong>DÄ°KKAT:</strong> AÅŸaÄŸÄ±daki kod bloklarÄ± bir <strong>\"kanÄ±t\"</strong> niteliÄŸindedir ve projeyi Ã§alÄ±ÅŸtÄ±rÄ±rken <strong>ATLANMALIDIR.</strong>\n",
        "</blockquote>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_xWX3uHNTaS",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "print(\"--- ADIM 4: Metin ParÃ§alarÄ± VektÃ¶rlere DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor ---\")\n",
        "\n",
        "print(\"Embedding modeli (all-mpnet-base-v2) yÃ¼kleniyor... LÃ¼tfen bekleyin.\")\n",
        "\n",
        "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "model_kwargs = {'device': 'cuda'}\n",
        "encode_kwargs = {'normalize_embeddings': True}\n",
        "\n",
        "try:\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=model_name,\n",
        "        model_kwargs=model_kwargs,\n",
        "        encode_kwargs=encode_kwargs\n",
        "    )\n",
        "    print(\"âœ… Embedding modeli baÅŸarÄ±yla yÃ¼klendi.\")\n",
        "\n",
        "    sample_chunk_content = chunks[0].page_content\n",
        "    vector = embeddings.embed_query(sample_chunk_content)\n",
        "\n",
        "    print(\"\\n--- Embedding Testi BaÅŸarÄ±lÄ± ---\")\n",
        "    print(f\"Ã–rnek metin parÃ§asÄ± (ilk 80 karakter): '{sample_chunk_content[:80]}...'\")\n",
        "    print(f\"OluÅŸturulan vektÃ¶rÃ¼n boyutu (kaÃ§ sayÄ±dan oluÅŸtuÄŸu): {len(vector)}\")\n",
        "    print(f\"VektÃ¶rÃ¼n ilk 5 deÄŸeri: {vector[:5]}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Hata: Embedding modeli yÃ¼klenemedi. Colab'de 'Runtime > Change runtime type' menÃ¼sÃ¼nden GPU'nun (T4) seÃ§ili olduÄŸundan emin olun. Hata detayÄ±: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<h3 style=\"color: #e06c75;\">2.2. GeliÅŸtirme SÃ¼recinde HÄ±zlÄ± Test âš¡</h3>\n",
        "<p>Nihai veritabanÄ±nÄ± oluÅŸturma iÅŸlemi 1.5 saat gibi oldukÃ§a uzun bir sÃ¼re aldÄ±ÄŸÄ±ndan, geliÅŸtirme dÃ¶ngÃ¼sÃ¼nÃ¼ hÄ±zlandÄ±rmak ve RAG akÄ±ÅŸÄ±nÄ±n tÃ¼m adÄ±mlarÄ±nÄ± (Embedding -> VeritabanÄ± OluÅŸturma -> Arama) hÄ±zlÄ±ca test edebilmek iÃ§in stratejik bir ara adÄ±m uyguladÄ±k. Bu adÄ±mda, yaklaÅŸÄ±k 300,000 parÃ§alÄ±k tam veri setinden, sadece ilk <strong>10,000 parÃ§ayÄ±</strong> alarak daha kÃ¼Ã§Ã¼k ve yÃ¶netilebilir bir alt kÃ¼me (subset) oluÅŸturduk.</p>\n",
        "<p>AÅŸaÄŸÄ±daki kod bloklarÄ± bu sÃ¼reci gÃ¶stermektedir:</p>\n",
        "<ol>\n",
        "<li><strong>Veri KÃ¼Ã§Ã¼ltme:</strong> Tam <code>chunks</code> listesinden <code>[:10000]</code> dilimleme (slicing) yÃ¶ntemiyle ilk 10,000 elemanÄ± seÃ§erek <code>test_chunks</code> adÄ±nda yeni bir liste oluÅŸturulur.</li>\n",
        "<li><strong>Test VeritabanÄ± Ä°nÅŸasÄ±:</strong> <code>Chroma.from_documents</code> fonksiyonu bu sefer, bu kÃ¼Ã§Ã¼k <code>test_chunks</code> listesiyle Ã§aÄŸrÄ±lÄ±r. Bu iÅŸlem, tam veri setiyle saatler sÃ¼rerken, bu alt kÃ¼me ile sadece birkaÃ§ dakika iÃ§inde tamamlanÄ±r. Bu bize, <code>embedding</code> modelinin, <code>ChromaDB</code>'nin ve genel RAG mantÄ±ÄŸÄ±nÄ±n doÄŸru yapÄ±landÄ±rÄ±ldÄ±ÄŸÄ±nÄ± hÄ±zlÄ±ca doÄŸrulama imkanÄ± tanÄ±mÄ±ÅŸtÄ±r.</li>\n",
        "</ol>\n",
        "<p>Bu \"hÄ±zlÄ± prototipleme\" yaklaÅŸÄ±mÄ±, bÃ¼yÃ¼k Ã¶lÃ§ekli iÅŸlemi baÅŸlatmadan Ã¶nce olasÄ± hatalarÄ± erken bir aÅŸamada tespit etmemizi saÄŸlayarak projenin geliÅŸtirme sÃ¼recini Ã¶nemli Ã¶lÃ§Ã¼de verimli hale getirmiÅŸtir.</p>"
      ],
      "metadata": {
        "id": "bL1rZzJFEjIr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhvFGPkci2fO"
      },
      "outputs": [],
      "source": [
        "print(\"--- HÄ±zlÄ± Test Ä°Ã§in Veri Seti KÃ¼Ã§Ã¼ltÃ¼lÃ¼yor ---\")\n",
        "\n",
        "print(f\"Orijinal parÃ§a (chunk) sayÄ±sÄ±: {len(chunks)}\")\n",
        "\n",
        "test_chunks = chunks[:10000]\n",
        "\n",
        "print(f\"Test iÃ§in kullanÄ±lacak parÃ§a sayÄ±sÄ±: {len(test_chunks)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylAZ1Qsxi7re"
      },
      "outputs": [],
      "source": [
        "print(\" VektÃ¶r VeritabanÄ± (HÄ±zlÄ± Test) OluÅŸturuluyor ---\")\n",
        "\n",
        "from langchain_chroma import Chroma\n",
        "from tqdm import tqdm # ilerleme Ã§ubuÄŸu iÃ§in\n",
        "\n",
        "persist_directory = 'neuro_coach_db_test' # Test iÃ§in farklÄ± bir klasÃ¶r adÄ±\n",
        "\n",
        "try:\n",
        "    # VeritabanÄ±nÄ± oluÅŸtururken artÄ±k 'chunks' yerine 'test_chunks' kullanÄ±yoruz!\n",
        "    vector_db_test = Chroma.from_documents(\n",
        "        documents=[test_chunks[0]],\n",
        "        embedding=embeddings,\n",
        "        persist_directory=persist_directory\n",
        "    )\n",
        "\n",
        "    remaining_chunks_test = test_chunks[1:]\n",
        "    batch_size = 100\n",
        "    for i in tqdm(range(0, len(remaining_chunks_test), batch_size), desc=\"Test chunk'larÄ± ekleniyor\"):\n",
        "        batch = remaining_chunks_test[i:i+batch_size]\n",
        "        vector_db_test.add_documents(documents=batch)\n",
        "\n",
        "    print(f\"\\nâœ… Test veritabanÄ± baÅŸarÄ±yla oluÅŸturuldu.\")\n",
        "    print(f\"Test veritabanÄ±ndaki vektÃ¶r sayÄ±sÄ±: {vector_db_test._collection.count()}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ Hata: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 style=\"color: #98c379;\">2.3. Nihai VeritabanÄ±nÄ±n OluÅŸturulmasÄ± ğŸ—ï¸</h3>\n",
        "<p>HÄ±zlÄ± testlerle tÃ¼m sistemin doÄŸru Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± doÄŸruladÄ±ktan sonra, projenin en kritik ve en uzun sÃ¼ren adÄ±mÄ± olan nihai bilgi bankasÄ±nÄ±n inÅŸasÄ±na geÃ§tik. Bu adÄ±mda, <strong>tam veri setini (~300,000 parÃ§a)</strong> kullanarak, chatbot'umuzun \"beynini\" oluÅŸturacak olan kalÄ±cÄ± vektÃ¶r veritabanÄ±nÄ± inÅŸa ediyoruz.</p>\n",
        "<p>Bu sÃ¼reÃ§te, bellek (RAM) taÅŸmasÄ± gibi sorunlarÄ± Ã¶nlemek ve sÃ¼reci izlenebilir kÄ±lmak iÃ§in verimli bir yÃ¶ntem izlenmiÅŸtir:</p>\n",
        "<ol>\n",
        "<li><strong>BaÅŸlatma (Initialization):</strong> VeritabanÄ±, <code>Chroma.from_documents</code> komutuyla sadece <strong>tek bir \"chunk\"</strong> kullanÄ±larak baÅŸlatÄ±lÄ±r. Bu, veritabanÄ± dosyalarÄ±nÄ±n diskte ilk kez oluÅŸturulmasÄ±nÄ± saÄŸlar.</li>\n",
        "<li><strong>Toplu Ekleme (Batch Processing):</strong> Geri kalan yÃ¼z binlerce \"chunk\", <code>for</code> dÃ¶ngÃ¼sÃ¼ iÃ§inde <strong>100'erli gruplar (batches)</strong> halinde veritabanÄ±na eklenir. <code>vector_db_final.add_documents()</code> metodu kullanÄ±larak yapÄ±lan bu toplu ekleme iÅŸlemi, her bir \"chunk\"Ä± tek tek iÅŸlemekten Ã§ok daha verimlidir.</li>\n",
        "<li><strong>Ä°zleme (Monitoring):</strong> TÃ¼m bu dÃ¶ngÃ¼, <code>tqdm</code> kÃ¼tÃ¼phanesi ile sarmalanmÄ±ÅŸtÄ±r. Bu, iÅŸlem sÄ±rasÄ±nda bize canlÄ± bir <strong>ilerleme Ã§ubuÄŸu</strong> sunarak, sÃ¼recin ne kadarÄ±nÄ±n tamamlandÄ±ÄŸÄ±nÄ±, ne kadar sÃ¼rdÃ¼ÄŸÃ¼nÃ¼ ve tahmini olarak ne zaman biteceÄŸini gÃ¶rmemizi saÄŸlar.</li>\n",
        "</ol>\n",
        "<p>Bu \"toplu iÅŸleme\" ve \"izleme\" yaklaÅŸÄ±mÄ±, bÃ¼yÃ¼k veri setleriyle Ã§alÄ±ÅŸÄ±rken hem sistem kaynaklarÄ±nÄ± verimli kullanmanÄ±n hem de uzun sÃ¼ren iÅŸlemleri kontrol altÄ±nda tutmanÄ±n en iyi pratiklerinden biridir.</p>"
      ],
      "metadata": {
        "id": "l-bfM80YHb-y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RksFOWnek9ql"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "print(\"--- NÄ°HAÄ° VERÄ°TABANI OLUÅTURMA ---\")\n",
        "\n",
        "# OluÅŸturulacak klasÃ¶rÃ¼n adÄ±\n",
        "persist_directory_final = 'neuro_coach_db_final'\n",
        "\n",
        "# EÄŸer klasÃ¶r daha Ã¶nce oluÅŸturulduysa, iÅŸlemi atla\n",
        "if os.path.exists(persist_directory_final):\n",
        "    print(f\"'{persist_directory_final}' klasÃ¶rÃ¼ zaten mevcut. OluÅŸturma adÄ±mÄ± atlanÄ±yor.\")\n",
        "    # Ä°stersen mevcut veritabanÄ±nÄ± yÃ¼kleyebilirsin\n",
        "    # vector_db_final = Chroma(persist_directory=persist_directory_final, embedding_function=embeddings)\n",
        "else:\n",
        "    # Ä°lk chunk ile veritabanÄ±nÄ± baÅŸlat\n",
        "    vector_db_final = Chroma.from_documents(\n",
        "        documents=[chunks[0]], # Orijinal 'chunks' listesini kullanÄ±yoruz\n",
        "        embedding=embeddings,\n",
        "        persist_directory=persist_directory_final\n",
        "    )\n",
        "\n",
        "    # Geri kalan tÃ¼m chunk'larÄ± ilerleme Ã§ubuÄŸu ile ekle\n",
        "    remaining_chunks_final = chunks[1:]\n",
        "    batch_size = 100 # 100'erli gruplar halinde\n",
        "    for i in tqdm(range(0, len(remaining_chunks_final), batch_size), desc=\"Nihai chunk'lar ekleniyor\"):\n",
        "        batch = remaining_chunks_final[i:i+batch_size]\n",
        "        vector_db_final.add_documents(documents=batch)\n",
        "\n",
        "    print(f\"\\nâœ… Nihai veritabanÄ± baÅŸarÄ±yla oluÅŸturuldu.\")\n",
        "    print(f\"VeritabanÄ±ndaki toplam vektÃ¶r sayÄ±sÄ±: {vector_db_final._collection.count()}\")\n",
        "\n",
        "print(\"\\nVeritabanÄ± oluÅŸturma iÅŸlemi tamamlandÄ±.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 style=\"color: #56b6c2;\">2.4. Bilgi BankasÄ±nÄ± KalÄ±cÄ± Hale Getirme (Yedekleme) ğŸ’¾</h3>\n",
        "<p>YaklaÅŸÄ±k 1.5 saat sÃ¼ren yoÄŸun bir iÅŸlemle oluÅŸturduÄŸumuz vektÃ¶r veritabanÄ±, Colab'in geÃ§ici depolama alanÄ±nda bulunmaktadÄ±r. Bu, Colab oturumu kapandÄ±ÄŸÄ±nda bu deÄŸerli verinin kaybolacaÄŸÄ± anlamÄ±na gelir. Bu uzun iÅŸlemi her seferinde tekrar yapmamak iÃ§in, oluÅŸturulan veritabanÄ±nÄ± kalÄ±cÄ± depolama alanÄ±mÄ±z olan <strong>Google Drive'a yedekliyoruz.</strong></p>\n",
        "<p>Bu sÃ¼reÃ§ aÅŸaÄŸÄ±daki adÄ±mlarÄ± iÃ§erir:</p>\n",
        "<ol>\n",
        "<li><strong>SÄ±kÄ±ÅŸtÄ±rma:</strong> <code>ChromaDB</code> tarafÄ±ndan oluÅŸturulan ve Ã§ok sayÄ±da kÃ¼Ã§Ã¼k dosyadan oluÅŸan <code>neuro_coach_db_final</code> klasÃ¶rÃ¼, taÅŸÄ±ma iÅŸlemini hÄ±zlandÄ±rmak ve tek bir dosya haline getirmek iÃ§in <code>!zip</code> komutuyla sÄ±kÄ±ÅŸtÄ±rÄ±larak bir <code>.zip</code> arÅŸivi oluÅŸturulur.</li>\n",
        "<li><strong>Google Drive BaÄŸlantÄ±sÄ±:</strong> <code>google.colab.drive</code> kÃ¼tÃ¼phanesi kullanÄ±larak Colab ortamÄ±, kiÅŸisel Google Drive hesabÄ±mÄ±za baÄŸlanÄ±r.</li>\n",
        "<li><strong>Kopyalama:</strong> OluÅŸturulan <code>.zip</code> arÅŸivi, <code>!cp</code> komutuyla Colab'in geÃ§ici diskinden, Google Drive'Ä±mÄ±zdaki <code>NeuroCoach_Project</code> adlÄ± Ã¶zel bir klasÃ¶rÃ¼n iÃ§ine kopyalanÄ±r.</li>\n",
        "</ol>\n",
        "<p>Bu yedekleme iÅŸlemi sayesinde, projenin sonraki tÃ¼m Ã§alÄ±ÅŸtÄ±rmalarÄ±nda bu uzun \"inÅŸa\" sÃ¼recini atlayÄ±p, doÄŸrudan Google Drive'daki bu hazÄ±r veritabanÄ±nÄ± yÃ¼kleyerek projemize dakikalar iÃ§inde baÅŸlayabiliriz.</p>"
      ],
      "metadata": {
        "id": "FyzMgpyvHylV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnFwTXM-4rtC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "print(\"--- OluÅŸturulan VeritabanÄ±nÄ± Google Drive'da Ã–zel Bir KlasÃ¶re Kaydetme ---\")\n",
        "\n",
        "# --- AYARLAR ---\n",
        "drive_folder_name = \"NeuroCoach_Project\"\n",
        "persist_directory_final = 'neuro_coach_db_final'\n",
        "zip_filename = 'neuro_coach_db_final.zip'\n",
        "# --- BÄ°TTÄ° ---\n",
        "\n",
        "drive_folder_path = f'/content/drive/MyDrive/{drive_folder_name}'\n",
        "drive_zip_path = f'{drive_folder_path}/{zip_filename}'\n",
        "colab_zip_path = f'/content/{zip_filename}'\n",
        "\n",
        "try:\n",
        "    # 1. Google Drive'Ä± baÄŸla (Ä°zin isteyecek)\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "    # 2. Drive'da hedef klasÃ¶rÃ¼ oluÅŸtur\n",
        "    if not os.path.exists(drive_folder_path):\n",
        "        print(f\"'{drive_folder_name}' klasÃ¶rÃ¼ Drive'da oluÅŸturuluyor...\")\n",
        "        os.makedirs(drive_folder_path)\n",
        "    else:\n",
        "        print(f\"'{drive_folder_name}' klasÃ¶rÃ¼ Drive'da zaten mevcut.\")\n",
        "\n",
        "    # 3. KlasÃ¶rÃ¼ sÄ±kÄ±ÅŸtÄ±r (bu iÅŸlem birkaÃ§ dakika sÃ¼rebilir)\n",
        "    print(f\"'{persist_directory_final}' klasÃ¶rÃ¼ sÄ±kÄ±ÅŸtÄ±rÄ±lÄ±yor...\")\n",
        "    !zip -r {colab_zip_path} {persist_directory_final}\n",
        "\n",
        "    # 4. SÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ dosyayÄ± Drive'a kopyala (bu iÅŸlem de birkaÃ§ dakika sÃ¼rebilir)\n",
        "    print(f\"'{zip_filename}' dosyasÄ± hedef Drive klasÃ¶rÃ¼ne kopyalanÄ±yor...\")\n",
        "    !cp {colab_zip_path} {drive_folder_path}/\n",
        "\n",
        "    print(f\"\\nâœ… BAÅARILI! VeritabanÄ±nÄ±z ÅŸu konuma kaydedildi: '{drive_zip_path}'\")\n",
        "    print(\"ArtÄ±k bu uzun iÅŸlemi bir daha yapmanÄ±za gerek yok!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Kaydetme sÄ±rasÄ±nda bir hata oluÅŸtu: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zhsaTTlbqX1"
      },
      "source": [
        "<div style=\"background-color: #282c34; padding: 20px; border-radius: 10px; border: 1px solid #56b6c2;\">\n",
        "<h1 style=\"color: #56b6c2; font-size: 32px; text-align: center; border-bottom: 2px solid #56b6c2; padding-bottom: 10px; margin-top: 0; text-shadow: 2px 2px 5px rgba(0,0,0,0.3);\">\n",
        "ğŸš€ BÃ¶lÃ¼m 3: HÄ±zlÄ± BaÅŸlangÄ±Ã§ - HazÄ±r Bilgi BankasÄ±nÄ± YÃ¼kleme\n",
        "</h1>\n",
        "<p style=\"font-size: 16px;\">BÃ¶lÃ¼m 2'de bir kez Ã§alÄ±ÅŸtÄ±rÄ±p Google Drive'a kaydettiÄŸimiz o devasa emek ve zamanÄ±n meyvelerini bu bÃ¶lÃ¼mde topluyoruz. Bu bÃ¶lÃ¼m, projeyi her baÅŸlattÄ±ÄŸÄ±mÄ±zda Ã§alÄ±ÅŸtÄ±racaÄŸÄ±mÄ±z \"hÄ±zlÄ± baÅŸlangÄ±Ã§\" rutinidir. 1.5 saatlik veritabanÄ± oluÅŸturma sÃ¼recini atlayarak, projemizi birkaÃ§ dakika iÃ§inde kullanÄ±ma hazÄ±r hale getirir.</p>\n",
        "<h3 style=\"color: #e5c07b;\">SÃ¼reÃ§ AdÄ±mlarÄ± <font color=\"#98c379\">âš™ï¸</font></h3>\n",
        "<p>AÅŸaÄŸÄ±daki kod bloÄŸu, bu hÄ±zlÄ± baÅŸlangÄ±Ã§ sÃ¼recini otomatize eder:</p>\n",
        "<ol>\n",
        "<li><strong>AkÄ±llÄ± Temizlik:</strong> Kod, baÅŸlamadan Ã¶nce Ã¶nceki Ã§alÄ±ÅŸtÄ±rmalardan kalmÄ±ÅŸ olabilecek eski veritabanÄ± klasÃ¶rlerini ve <code>.zip</code> dosyalarÄ±nÄ± otomatik olarak siler. Bu, olasÄ± dosya Ã§akÄ±ÅŸmalarÄ±nÄ± Ã¶nler.</li>\n",
        "<li><strong>Google Drive BaÄŸlantÄ±sÄ±:</strong> Projemizi, yedeklenmiÅŸ veritabanÄ±nÄ±n bulunduÄŸu Google Drive hesabÄ±mÄ±za baÄŸlar.</li>\n",
        "<li><strong>VeritabanÄ±nÄ± Getirme:</strong> Drive'daki sÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ veritabanÄ± (<code>.zip</code>) dosyasÄ±nÄ± Colab'in hÄ±zlÄ± yerel diskine kopyalar ve arÅŸivi aÃ§ar.</li>\n",
        "<li><strong>Embedding Modelini YÃ¼kleme:</strong> VeritabanÄ±ndaki vektÃ¶rleri \"anlayabilmek\" iÃ§in, o veritabanÄ±nÄ± oluÅŸtururken kullandÄ±ÄŸÄ±mÄ±z <strong>aynÄ±</strong> <code>embedding</code> modelini tekrar hafÄ±zaya yÃ¼kler. Bu, tutarlÄ±lÄ±k iÃ§in kritik bir adÄ±mdÄ±r.</li>\n",
        "<li><strong>VeritabanÄ±nÄ± Aktif Etme:</strong> Son olarak, <code>Chroma</code>'ya diskteki klasÃ¶rÃ¼n yolunu gÃ¶stererek, hazÄ±r bilgi bankasÄ±nÄ± <code>beyin</code> adÄ±nda bir deÄŸiÅŸkene atar ve kullanÄ±ma hazÄ±r hale getirir.</li>\n",
        "</ol>\n",
        "<blockquote style=\"border-left: 4px solid #56b6c2; padding-left: 15px; margin: 10px 0; color: #abb2bf;\">\n",
        "</blockquote>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_jgPpitu7_w",
        "outputId": "af2da5ab-70b6-490e-cbf8-69a79ba87214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eskiden kalma veritabanÄ± klasÃ¶rÃ¼ bulundu ve temizleniyor...\n",
            "Eskiden kalma .zip dosyasÄ± bulundu ve temizleniyor...\n",
            "Beynin dÃ¼ÅŸÃ¼nme ÅŸekli yÃ¼kleniyor...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Beyin kullanÄ±ma hazÄ±rlanÄ±yor...\n",
            "âœ… Beyin baÅŸarÄ±yla getirildi ve kullanÄ±ma hazÄ±r! Ä°Ã§inde 299942 adet bilgi parÃ§acÄ±ÄŸÄ± var.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# Kod, baÅŸlamadan Ã¶nce eskiden kalma dosyalarÄ± kontrol edip silecek.\n",
        "if os.path.exists('/content/neuro_coach_db_final'):\n",
        "    print(\"Eskiden kalma veritabanÄ± klasÃ¶rÃ¼ bulundu ve temizleniyor...\")\n",
        "    !rm -rf /content/neuro_coach_db_final\n",
        "\n",
        "if os.path.exists('/content/neuro_coach_db_final.zip'):\n",
        "    print(\"Eskiden kalma .zip dosyasÄ± bulundu ve temizleniyor...\")\n",
        "    !rm -f /content/neuro_coach_db_final.zip\n",
        "# --- TEMÄ°ZLÄ°K BÄ°TTÄ° ---\n",
        "\n",
        "# Beynin \"dÃ¼ÅŸÃ¼nme\" ÅŸeklini (embedding modelini) tekrar yÃ¼kleyelim.\n",
        "print(\"Beynin dÃ¼ÅŸÃ¼nme ÅŸekli yÃ¼kleniyor...\")\n",
        "embeddings_model = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
        "\n",
        ")\n",
        "\n",
        "# Åimdi Google Drive'a baÄŸlanalÄ±m.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Beyin dosyasÄ±nÄ± (.zip) Drive'dan Colab'e kopyalayalÄ±m\n",
        "!cp /content/drive/MyDrive/NeuroCoach_Project/neuro_coach_db_final.zip /content/\n",
        "\n",
        "# Beyin dosyasÄ±nÄ± aÃ§alÄ±m (ArtÄ±k soru sormayacak Ã§Ã¼nkÃ¼ eski klasÃ¶rÃ¼ sildik)\n",
        "!unzip -q /content/neuro_coach_db_final.zip -d /content/\n",
        "\n",
        "# Son olarak, aÃ§tÄ±ÄŸÄ±mÄ±z beyin klasÃ¶rÃ¼nÃ¼ kullanÄ±ma hazÄ±r hale getirelim\n",
        "print(\"Beyin kullanÄ±ma hazÄ±rlanÄ±yor...\")\n",
        "beyin = Chroma(\n",
        "    persist_directory='neuro_coach_db_final',\n",
        "    embedding_function=embeddings_model\n",
        ")\n",
        "\n",
        "print(f\"âœ… Beyin baÅŸarÄ±yla getirildi ve kullanÄ±ma hazÄ±r! Ä°Ã§inde {beyin._collection.count()} adet bilgi parÃ§acÄ±ÄŸÄ± var.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #282c34; padding: 20px; border-radius: 10px; border: 1px solid #e06c75;\">\n",
        "<h1 style=\"color: #e06c75; font-size: 32px; text-align: center; border-bottom: 2px solid #e06c75; padding-bottom: 10px; margin-top: 0; text-shadow: 2px 2px 5px rgba(0,0,0,0.3);\">\n",
        "ğŸŒ BÃ¶lÃ¼m 3.5: Ã‡ok Dilli Yeteneklerin KazandÄ±rÄ±lmasÄ±\n",
        "</h1>\n",
        "<p style=\"font-size: 16px;\">Bilgi bankamÄ±z Ä°ngilizce metinlerden oluÅŸtuÄŸu iÃ§in, RAG mimarisinin arama (Retrieval) adÄ±mÄ±nÄ±n verimli Ã§alÄ±ÅŸabilmesi adÄ±na kullanÄ±cÄ± sorgularÄ±nÄ±n da Ä°ngilizce olmasÄ± gerekmektedir. Bu bÃ¶lÃ¼mde, chatbot'umuzu evrensel hale getirmek ve farklÄ± dillerdeki sorularÄ± anlayabilmesini saÄŸlamak iÃ§in iki temel yardÄ±mcÄ± fonksiyon tanÄ±mlÄ±yoruz. Bu fonksiyonlar, Gemini modelinin dil yeteneklerini akÄ±llÄ±ca kullanarak bir \"evrensel tercÃ¼man\" gÃ¶revi gÃ¶rÃ¼r.</p>\n",
        "<h3 style=\"color: #e5c07b;\">Fonksiyonlar ve GÃ¶revleri <font color=\"#c678dd\">ğŸ› ï¸</font></h3>\n",
        "<ol>\n",
        "<li>\n",
        "<strong><code>detect_language(text)</code> - Dil Tespiti:</strong>\n",
        "<p>Bu fonksiyon, kullanÄ±cÄ±dan gelen metni alÄ±r ve Gemini modeline basit bir prompt (\"Bu metin hangi dilde?\") gÃ¶ndererek metnin dil kodunu (Ã¶rn: 'tr', 'en') tespit eder. Bu, gereksiz Ã§eviri iÅŸlemlerini Ã¶nlemek iÃ§in kritik bir ilk adÄ±mdÄ±r.</p>\n",
        "</li>\n",
        "<li>\n",
        "<strong><code>translate_to_english(text, source_language)</code> - Ä°ngilizce'ye Ã‡eviri:</strong>\n",
        "<p>EÄŸer tespit edilen dil Ä°ngilizce deÄŸilse, bu fonksiyon devreye girer. Metni, Gemini modeline \"Bu metni Ä°ngilizce'ye Ã§evir\" prompt'u ile gÃ¶ndererek, RAG sistemimizin arama yapabileceÄŸi standart bir formata dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. Metin zaten Ä°ngilizce ise, bu adÄ±mÄ± atlayarak verimlilik saÄŸlar.</p>\n",
        "</li>\n",
        "</ol>\n",
        "<blockquote style=\"border-left: 4px solid #e06c75; padding-left: 15px; margin: 10px 0; color: #abb2bf;\">\n",
        "ğŸ’¡ Bu yaklaÅŸÄ±m, ayrÄ± bir Ã§eviri servisi API'sine ihtiyaÃ§ duymadan, zaten kullanmakta olduÄŸumuz gÃ¼Ã§lÃ¼ Gemini modelini hem dil tespiti hem de Ã§eviri iÃ§in kullanarak projemizi daha basit ve daha entegre bir yapÄ±da tutmamÄ±zÄ± saÄŸlar.\n",
        "</blockquote>\n",
        "</div>"
      ],
      "metadata": {
        "id": "PLIs_trvJHL9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwXNWIvsw6cx",
        "outputId": "1e1d9204-61df-43ca-9722-eb56401a53f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ã‡eviri ve dil tespiti iÃ§in yardÄ±mcÄ± fonksiyonlar hazÄ±rlanÄ±yor...\n",
            "âœ… YardÄ±mcÄ± fonksiyonlar hazÄ±r.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "print(\"Ã‡eviri ve dil tespiti iÃ§in yardÄ±mcÄ± fonksiyonlar hazÄ±rlanÄ±yor...\")\n",
        "\n",
        "# Bu model, sadece bu hÃ¼credeki kÃ¼Ã§Ã¼k iÅŸler iÃ§in kullanÄ±lacak.\n",
        "helper_model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "def detect_language(text: str) -> str:\n",
        "    \"\"\"Verilen metnin dil kodunu ('en', 'tr' vb.) dÃ¶ndÃ¼rÃ¼r.\"\"\"\n",
        "    try:\n",
        "        prompt = f\"What language is this text? Answer with only the two-letter ISO 639-1 code. Text: '{text}'\"\n",
        "        response = helper_model.generate_content(prompt)\n",
        "        language_code = response.text.strip().lower()\n",
        "        print(f\"Tespit edilen dil: {language_code}\")\n",
        "        return language_code\n",
        "    except Exception as e:\n",
        "        print(f\"Dil tespiti sÄ±rasÄ±nda hata: {e}\")\n",
        "        return \"en\" # Hata olursa, varsayÄ±lan olarak Ä°ngilizce kabul et\n",
        "\n",
        "def translate_to_english(text: str, source_language: str) -> str:\n",
        "    \"\"\"Verilen metni, kaynak dilini bilerek Ä°ngilizce'ye Ã§evirir.\"\"\"\n",
        "    if \"en\" in source_language:\n",
        "        print(\"Metin zaten Ä°ngilizce, Ã§eviri atlanÄ±yor.\")\n",
        "        return text\n",
        "\n",
        "    try:\n",
        "        print(f\"'{source_language}' dilinden Ä°ngilizce'ye Ã§evriliyor...\")\n",
        "        prompt = f\"Translate the following text to English. Respond with only the translated text: '{text}'\"\n",
        "        response = helper_model.generate_content(prompt)\n",
        "        translated_text = response.text.strip()\n",
        "        print(f\"Ã‡eviri: {translated_text}\")\n",
        "        return translated_text\n",
        "    except Exception as e:\n",
        "        print(f\"Ã‡eviri sÄ±rasÄ±nda hata: {e}\")\n",
        "        return text\n",
        "\n",
        "print(\"âœ… YardÄ±mcÄ± fonksiyonlar hazÄ±r.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #282c34; padding: 20px; border-radius: 10px; border: 1px solid #98c379;\">\n",
        "<h1 style=\"color: #98c379; font-size: 32px; text-align: center; border-bottom: 2px solid #98c379; padding-bottom: 10px; margin-top: 0; text-shadow: 2px 2px 5px rgba(0,0,0,0.3);\">\n",
        "âš™ï¸ BÃ¶lÃ¼m 4: Ana Chatbot Motorunun Ä°nÅŸasÄ±\n",
        "</h1>\n",
        "<p style=\"font-size: 16px;\">Bu bÃ¶lÃ¼mde, projemizin kalbini ve beynini oluÅŸturan ana RAG (Retrieval Augmented Generation) motorunu inÅŸa ediyoruz. Bu motor, hem Ã¶nceki konuÅŸmalarÄ± hatÄ±rlayabilen (hafÄ±zalÄ±) hem de farklÄ± dillerde talimat alabilen (Ã§ok dilli) geliÅŸmiÅŸ bir yapÄ±ya sahiptir. Bu adÄ±mlarÄ±n sonunda, Gradio arayÃ¼zÃ¼ne baÄŸlanmaya hazÄ±r, tam iÅŸlevsel bir chatbot mantÄ±ÄŸÄ±mÄ±z olacak.</p>\n",
        "<h3 style=\"color: #e5c07b;\">4.1. Temel BileÅŸenlerin HazÄ±rlanmasÄ± <font color=\"#61afef\">ğŸ§©</font></h3>\n",
        "<p>Zincirimizi oluÅŸturmadan Ã¶nce, onu oluÅŸturan ana parÃ§alarÄ± hazÄ±rlÄ±yoruz:</p>\n",
        "<ul>\n",
        "<li><strong>Retriever (Arama YapÄ±cÄ±):</strong> Bir Ã¶nceki bÃ¶lÃ¼mde yÃ¼klediÄŸimiz <code>beyin</code> (ChromaDB veritabanÄ±) deÄŸiÅŸkenini, LangChain'in anlayacaÄŸÄ± bir \"arama motoruna\" dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yoruz. Her sorguda en alakalÄ± 5 belgeyi getirecek ÅŸekilde ayarlanmÄ±ÅŸtÄ±r.</li>\n",
        "<li><strong>LLM (Dil Modeli):</strong> CevaplarÄ± Ã¼retecek olan <code>gemini-2.5-flash</code> modelini LangChain ile uyumlu hale getiriyoruz.</li>\n",
        "<li><strong>Memory (HafÄ±za):</strong> <code>ConversationBufferMemory</code> ile chatbot'umuzun sohbet geÃ§miÅŸini saklayacaÄŸÄ± geÃ§ici bir hafÄ±za alanÄ± oluÅŸturuyoruz.</li>\n",
        "</ul>\n",
        "<br>\n",
        "<h3 style=\"color: #e5c07b;\">4.2. Ã‡ok Dilli Prompt ÅablonlarÄ± <font color=\"#c678dd\">ğŸŒ</font></h3>\n",
        "<p>Chatbot'umuzun, kullanÄ±cÄ±nÄ±n sorduÄŸu dile gÃ¶re cevap verebilmesi iÃ§in iki ayrÄ± \"gÃ¶rev tanÄ±mÄ±\" (prompt ÅŸablonu) hazÄ±rlÄ±yoruz. Bir tanesi TÃ¼rkÃ§e cevap Ã¼retmesi iÃ§in talimatlar iÃ§erirken, diÄŸeri Ä°ngilizce cevap Ã¼retmesi iÃ§in talimatlar iÃ§erir. Bu ÅŸablonlar, bir sonraki bÃ¶lÃ¼mde (Gradio) kullanÄ±cÄ±nÄ±n diline gÃ¶re dinamik olarak seÃ§ilip zincire enjekte edilecektir.</p>\n",
        "<br>\n",
        "<h3 style=\"color: #e5c07b;\">4.3. HafÄ±zalÄ± Ana Zincirin OluÅŸturulmasÄ± <font color=\"#98c379\">ğŸ”—</font></h3>\n",
        "<p>TÃ¼m parÃ§alarÄ±, LangChain'in gÃ¼Ã§lÃ¼ ve hazÄ±r zincirlerinden biri olan <code>ConversationalRetrievalChain</code> ile birleÅŸtiriyoruz. Bu zincir, bizim iÃ§in birÃ§ok karmaÅŸÄ±k iÅŸi otomatik olarak yapar:</p>\n",
        "<ol>\n",
        "<li>Yeni soruyu ve <strong>hafÄ±zadaki eski konuÅŸmalarÄ±</strong> birleÅŸtirerek daha akÄ±llÄ± bir arama sorgusu oluÅŸturur.</li>\n",
        "<li>Bu sorguyla <strong>Retriever</strong>'Ä± kullanarak veritabanÄ±nda arama yapar.</li>\n",
        "<li>Bulunan belgeleri, sohbet geÃ§miÅŸini ve yeni soruyu <strong>LLM</strong>'e gÃ¶ndererek nihai cevabÄ± Ã¼retir.</li>\n",
        "<li>Yeni soru ve cevabÄ± otomatik olarak <strong>hafÄ±zaya</strong> ekler.</li>\n",
        "<li><code>return_source_documents=True</code> parametresi sayesinde, cevabÄ± Ã¼retirken kullandÄ±ÄŸÄ± kaynak belgeleri de bize sunar.</li>\n",
        "</ol>\n",
        "<blockquote style=\"border-left: 4px solid #98c379; padding-left: 15px; margin: 10px 0; color: #abb2bf;\">\n",
        "ğŸ’¡ Bu \"hazÄ±r zincir\" yaklaÅŸÄ±mÄ±, karmaÅŸÄ±k LCEL yapÄ±larÄ± kurmadan, hafÄ±za yÃ¶netimini ve RAG akÄ±ÅŸÄ±nÄ± son derece basit ve okunabilir bir kodla uygulamamÄ±zÄ± saÄŸlar.\n",
        "</blockquote>\n",
        "</div>"
      ],
      "metadata": {
        "id": "ffm5gJj6JjY7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eP_TIlj6vuzF",
        "outputId": "ccd7f79c-3418-4c2c-977c-050992cd0146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HafÄ±zalÄ± temel motor ve Ã§ok dilli prompt'lar hazÄ±rlanÄ±yor...\n",
            "âœ… Kaynak gÃ¶sterebilen, hafÄ±zalÄ± temel motor baÅŸarÄ±yla oluÅŸturuldu.\n",
            "\n",
            "--- Test AÅŸamasÄ± ---\n",
            "CEVAP: Erteleme (procrastination), Ã¶nemli gÃ¶revleri isteyerek erteleyip, daha az Ã¶nemli veya keyifli aktivitelere yÃ¶nelme eylemidir.\n",
            "\n",
            "Metne gÃ¶re erteleme:\n",
            "*   Dikkatimizi gerektiren gÃ¶revleri geciktirme veya erteleme eylemidir.\n",
            "*   Daha fazla Ã¶neme veya aciliyete sahip bir gÃ¶reve yÃ¶nelmek yerine, daha az Ã¶nemli veya keyifli bir ÅŸeyi yapmayÄ± gÃ¶nÃ¼llÃ¼ olarak seÃ§me davranÄ±ÅŸÄ±dÄ±r.\n",
            "*   Motivasyon eksikliÄŸi, kÃ¶tÃ¼ zaman yÃ¶netimi becerileri, baÅŸarÄ±sÄ±zlÄ±k veya baÅŸarÄ± korkusu gibi faktÃ¶rlerden kaynaklanabilir.\n",
            "*   PopÃ¼ler inanÄ±ÅŸÄ±n aksine, zaman yÃ¶netimi veya tembellikle ilgili olmayÄ±p, gelecekteki olaylar hakkÄ±nda kÃ¶tÃ¼ duygusal dÃ¼zenlemeyle ilgilidir.\n",
            "KAYNAK SAYISI: 5\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "print(\"HafÄ±zalÄ± temel motor ve Ã§ok dilli prompt'lar hazÄ±rlanÄ±yor...\")\n",
        "\n",
        "# 1. Temel BileÅŸenler\n",
        "arama_yapici = beyin.as_retriever(search_kwargs={\"k\": 5})\n",
        "llm_for_chain = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)\n",
        "\n",
        "# 2. HafÄ±za Nesnesi\n",
        "memory = ConversationBufferMemory(\n",
        "    memory_key='chat_history',\n",
        "    return_messages=True,\n",
        "    output_key='answer'\n",
        ")\n",
        "\n",
        "# 3. FARKLI DÄ°LLER Ä°Ã‡Ä°N PROMPT ÅABLONLARI\n",
        "# Bu prompt'lar, zincirin iÃ§ine sonradan enjekte edilecek.\n",
        "prompt_tr_template = \"\"\"Sen 'NÃ¶robilim asistanÄ±sÄ±n. KonuÅŸma geÃ§miÅŸini ({chat_history}) dikkate alarak, sana verilen yeni bilgileri ({context}) kullanarak kullanÄ±cÄ±nÄ±n yeni sorusuna ({question}) TÃœRKÃ‡E cevap ver. CevabÄ±n yardÄ±msever ve anlaÅŸÄ±lÄ±r olsun.\"\"\"\n",
        "prompt_en_template = \"\"\"You are 'Neuroscience assistant'. Considering the chat history ({chat_history}), answer the user's new question ({question}) in ENGLISH, using the new context ({context}). Be helpful and clear.\"\"\"\n",
        "\n",
        "prompt_tr = PromptTemplate.from_template(prompt_tr_template)\n",
        "prompt_en = PromptTemplate.from_template(prompt_en_template)\n",
        "\n",
        "\n",
        "# 4. TEMEL HafÄ±zalÄ± Zincir\n",
        "conversational_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm=llm_for_chain,\n",
        "    retriever=arama_yapici,\n",
        "    memory=memory,\n",
        "    output_key='answer',\n",
        "    return_source_documents=True\n",
        "    # -------------------------\n",
        ")\n",
        "\n",
        "print(\"âœ… Kaynak gÃ¶sterebilen, hafÄ±zalÄ± temel motor baÅŸarÄ±yla oluÅŸturuldu.\")\n",
        "\n",
        "print(\"\\n--- Test AÅŸamasÄ± ---\")\n",
        "soru1 = \"Erteleme (procrastination) nedir?\"\n",
        "result = conversational_chain.invoke({\"question\": soru1})\n",
        "\n",
        "print(\"CEVAP:\", result['answer'])\n",
        "print(\"KAYNAK SAYISI:\", len(result['source_documents']))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #282828; padding: 20px; border-radius: 10px; border: 1px solid #d3869b;\">\n",
        "<h1 style=\"color: #d3869b; font-size: 32px; text-align: center; border-bottom: 2px solid #d3869b; padding-bottom: 10px; margin-top: 0; text-shadow: 2px 2px 5px rgba(0,0,0,0.3);\">\n",
        "ğŸ¨ BÃ¶lÃ¼m 5: Ä°nteraktif Web ArayÃ¼zÃ¼ (Gradio)\n",
        "</h1>\n",
        "<p style=\"font-size: 16px;\">Projemizin son adÄ±mÄ±nda, Ã¶nceki bÃ¶lÃ¼mlerde inÅŸa ettiÄŸimiz gÃ¼Ã§lÃ¼ ve akÄ±llÄ± chatbot motorunu, kullanÄ±cÄ±larÄ±n kolayca etkileÅŸime girebileceÄŸi modern ve ÅŸÄ±k bir web arayÃ¼zÃ¼ ile buluÅŸturuyoruz. Bu, projemizin teknik yeteneklerini son kullanÄ±cÄ±ya sunan en Ã¶nemli vitrinidir.</p>\n",
        "<h3 style=\"color: #83a598;\">5.1. ArayÃ¼z TasarÄ±mÄ± ve Felsefesi âœ¨</h3>\n",
        "<p>ArayÃ¼zÃ¼n tasarÄ±mÄ±nda, projenin \"nÃ¶robilim\" ve \"teknoloji\" temalarÄ±nÄ± yansÄ±tan, fÃ¼tÃ¼ristik ve kullanÄ±cÄ± dostu bir yaklaÅŸÄ±m benimsenmiÅŸtir:</p>\n",
        "<ul>\n",
        "<li><strong>Ã–zel TasarÄ±m (CSS):</strong> ArayÃ¼z, standart Gradio gÃ¶rÃ¼nÃ¼mÃ¼nÃ¼n dÄ±ÅŸÄ±na Ã§Ä±karak, Ã¶zel CSS kodlarÄ± ile tamamen kiÅŸiselleÅŸtirilmiÅŸtir. Kozmik temalÄ± bir arkaplan resmi, \"buzlu cam\" efekti veren yarÄ± ÅŸeffaf ana panel ve markalaÅŸma iÃ§in Ã¶zel logo ve font kullanÄ±mÄ± gibi modern web tasarÄ±m teknikleri uygulanmÄ±ÅŸtÄ±r.</li>\n",
        "<li><strong>BileÅŸen YerleÅŸimi (<code>gr.Blocks</code>):</strong> Standart <code>ChatInterface</code> yerine, arayÃ¼z bileÅŸenleri (logo, baÅŸlÄ±k, sohbet penceresi, metin kutusu) Ã¼zerinde tam kontrol saÄŸlayan <code>gr.Blocks</code> yapÄ±sÄ± kullanÄ±lmÄ±ÅŸtÄ±r. Bu sayede, logo ve baÅŸlÄ±k yan yana hizalanarak profesyonel bir gÃ¶rÃ¼nÃ¼m elde edilmiÅŸtir.</li>\n",
        "</ul>\n",
        "<br>\n",
        "<h3 style=\"color: #83a598;\">5.2. ArayÃ¼z MantÄ±ÄŸÄ± ve Ã‡alÄ±ÅŸma AkÄ±ÅŸÄ± ğŸ§ </h3>\n",
        "<p>GÃ¶rsel tasarÄ±mÄ±n arkasÄ±nda, Ã¶nceki bÃ¶lÃ¼mlerde oluÅŸturduÄŸumuz tÃ¼m RAG mantÄ±ÄŸÄ±nÄ± yÃ¶neten akÄ±llÄ± bir fonksiyon yatmaktadÄ±r:</p>\n",
        "<ol>\n",
        "<li><strong><code>get_neuro_coach_response()</code> Fonksiyonu:</strong> Bu \"ana beyin\" fonksiyonu, Gradio arayÃ¼zÃ¼nden gelen her bir kullanÄ±cÄ± mesajÄ±nÄ± alÄ±r.</li>\n",
        "<li><strong>Ã‡ok Dilli Ä°ÅŸlem:</strong> Fonksiyon, BÃ¶lÃ¼m 3.5'teki yardÄ±mcÄ± fonksiyonlarÄ± Ã§aÄŸÄ±rarak mesajÄ±n dilini tespit eder ve gerekirse Ä°ngilizce'ye Ã§evirir.</li>\n",
        "<li><strong>Dinamik Prompting:</strong> BÃ¶lÃ¼m 4'te hazÄ±rlanan, dile Ã¶zel prompt ÅŸablonlarÄ±ndan uygun olanÄ± seÃ§er ve hafÄ±zalÄ± ana zincirin (<code>conversational_chain</code>) gÃ¶rev tanÄ±mÄ±nÄ± o anki konuÅŸmanÄ±n diline gÃ¶re gÃ¼nceller.</li>\n",
        "<li><strong>Cevap Ãœretimi:</strong> GÃ¼ncellenmiÅŸ zinciri Ã§alÄ±ÅŸtÄ±rarak nihai, hem hafÄ±zalÄ± hem de doÄŸru dilde cevabÄ± Ã¼retir ve arayÃ¼ze geri dÃ¶ndÃ¼rÃ¼r.</li>\n",
        "</ol>\n",
        "<blockquote style=\"border-left: 4px solid #d3869b; padding-left: 15px; margin: 10px 0; color: #d4be98;\">\n",
        "ğŸš€ <strong>SonuÃ§:</strong> Bu hÃ¼cre Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda, herkesle paylaÅŸÄ±labilen bir \"Public URL\" oluÅŸturulur. Bu link Ã¼zerinden eriÅŸilen arayÃ¼z, projemizin tÃ¼m yeteneklerini (hafÄ±za, Ã§ok dillilik, RAG) son kullanÄ±cÄ±ya sunan, tam iÅŸlevsel bir web uygulamasÄ±dÄ±r.\n",
        "</blockquote>\n",
        "</div>"
      ],
      "metadata": {
        "id": "63MC9MGaKE06"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxoj5_G9Lsje"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import time\n",
        "import re\n",
        "\n",
        "print(\"Projenin nihai arayÃ¼zÃ¼ inÅŸa ediliyor...\")\n",
        "\n",
        "# --- GÃ–RSEL TASARIM (CSS ve URL'ler) ---\n",
        "LOGO_URL = \"https://github.com/Fatmanurkntr/Neuroscience-Chatbot/blob/main/chatbotlogo1.png?raw=true\"\n",
        "BACKGROUND_IMAGE_URL = \"https://github.com/Fatmanurkntr/Neuroscience-Chatbot/blob/main/neuro.jpg?raw=true\"\n",
        "\n",
        "# TÃ¼m gÃ¶rsel ayarlarÄ± iÃ§eren CSS kodu.\n",
        "custom_css = f\"\"\"\n",
        "@import url('https://fonts.googleapis.com/css2?family=Poppins:wght@400;600;700&display=swap');\n",
        "\n",
        "body, .gradio-container {{\n",
        "    font-family: 'Poppins', sans-serif;\n",
        "    background-image: url('{BACKGROUND_IMAGE_URL}');\n",
        "    background-size: cover;\n",
        "    background-position: center;\n",
        "    background-attachment: fixed;\n",
        "}}\n",
        "\n",
        "#app_container {{\n",
        "    max-width: 800px;\n",
        "    margin: 40px auto;\n",
        "    background-color: rgba(20, 30, 48, 0.75);\n",
        "    backdrop-filter: blur(15px);\n",
        "    border-radius: 20px;\n",
        "    padding: 30px;\n",
        "    border: 1px solid rgba(255, 255, 255, 0.1);\n",
        "}}\n",
        "\n",
        "/* BaÅŸlÄ±ÄŸÄ± saran ana konteyner iÃ§in Flexbox ayarlarÄ± */\n",
        "#header_container {{\n",
        "    display: flex !important;\n",
        "    flex-direction: row !important;\n",
        "    justify-content: center !important;\n",
        "    align-items: center !important;\n",
        "    margin-bottom: 25px !important;\n",
        "    gap: 20px !important;\n",
        "}}\n",
        "\n",
        "/* Logo'nun kendisi iÃ§in boyut ayarÄ± */\n",
        "#header_logo img {{\n",
        "    width: 80px !important;\n",
        "    height: 80px !important;\n",
        "    min-width: 80px !important;\n",
        "}}\n",
        "\n",
        "/* Metinleri saran grup iÃ§in ayarlar */\n",
        "#header_text_group {{\n",
        "    display: flex !important;\n",
        "    flex-direction: column !important;\n",
        "    align-items: flex-start !important;\n",
        "}}\n",
        "\n",
        "/* Ana BaÅŸlÄ±k ve Alt BaÅŸlÄ±k stilleri */\n",
        "#header_title {{ color: #FFFFFF; font-size: 32px; font-weight: 700; margin: 0; padding: 0; line-height: 1.2; }}\n",
        "#header_subtitle {{ color: #D1D5DB; font-size: 16px; margin-top: 5px; padding: 0; }}\n",
        "\n",
        "/* Sohbet baloncuklarÄ± ve diÄŸer stiller */\n",
        "#main_chatbot .user {{ background: linear-gradient(to right, rgba(79, 70, 229, 0.8), rgba(124, 58, 237, 0.8)) !important; }}\n",
        "#main_chatbot .bot {{ background-color: rgba(55, 65, 81, 0.8) !important; }}\n",
        "\"\"\"\n",
        "\n",
        "# --- ANA MANTIK FONKSÄ°YONU (Gradio iÃ§in Ã¶zel) ---\n",
        "def get_neuro_coach_response(message: str, history: list):\n",
        "    \"\"\"\n",
        "    Bu \"ana beyin\" fonksiyonu, Gradio'dan gelen her soru iÃ§in tÃ¼m RAG sÃ¼recini yÃ¶netir.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"--- ArayÃ¼zden Gelen Soru: {message} ---\")\n",
        "\n",
        "    try:\n",
        "        language = detect_language(message)\n",
        "        english_question = translate_to_english(message, language)\n",
        "\n",
        "        if language == \"tr\":\n",
        "            selected_prompt = prompt_tr\n",
        "        else:\n",
        "            selected_prompt = prompt_en\n",
        "\n",
        "        conversational_chain.combine_docs_chain.llm_chain.prompt = selected_prompt\n",
        "\n",
        "        result = conversational_chain.invoke({\"question\": english_question})\n",
        "        answer = result.get('answer', \"ÃœzgÃ¼nÃ¼m, bir cevap Ã¼retemedim.\")\n",
        "\n",
        "        print(f\"--- Ãœretilen Cevap ---\")\n",
        "        return answer\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"!!!!!! HATA OLUÅTU: {e} !!!!!!\")\n",
        "        return f\"ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu: {e}\"\n",
        "\n",
        "# --- 3. ARAYÃœZÃœN Ä°NÅASI VE CANLANDIRILMASI ---\n",
        "with gr.Blocks(css=custom_css, theme=None, title=\"NÃ¶robilim AsistanÄ±\") as demo:\n",
        "\n",
        "    with gr.Column(elem_id=\"app_container\"):\n",
        "\n",
        "        # BaÅŸlÄ±k BÃ¶lÃ¼mÃ¼\n",
        "        with gr.Row(elem_id=\"header_container\"):\n",
        "            gr.Image(value=LOGO_URL, elem_id=\"header_logo\", show_download_button=False, container=False, show_fullscreen_button=False, scale=0)\n",
        "            with gr.Column(elem_id=\"header_text_group\", scale=1):\n",
        "                gr.Markdown(\"# NÃ¶robilim AsistanÄ±\", elem_id=\"header_title\")\n",
        "                gr.Markdown(\"Zihninizin karmaÅŸÄ±k haritasÄ±nÄ± keÅŸfedin. Motivasyon, erteleme ve alÄ±ÅŸkanlÄ±klarÄ±nÄ±zÄ±n ardÄ±ndaki nÃ¶robilimsel sÄ±rlarÄ± aydÄ±nlatmak iÃ§in bir soru sorun.\", elem_id=\"header_subtitle\")\n",
        "\n",
        "        # 1. Sohbet penceresi\n",
        "        chatbot = gr.Chatbot(height=450, render_markdown=True, elem_id=\"main_chatbot\", label=\"Sohbet\")\n",
        "\n",
        "        # 2. Mesaj yazma kutusu\n",
        "        msg = gr.Textbox(placeholder=\"Ã–rn: 'Erteleme alÄ±ÅŸkanlÄ±ÄŸÄ±ndan nasÄ±l kurtulurum?'\", show_label=False)\n",
        "\n",
        "        # 3. Ã–rnekler\n",
        "        gr.Examples(\n",
        "            [\"Erteleme nedir?\", \"Peki bununla nasÄ±l baÅŸa Ã§Ä±kabilirim?\", \"How to build a new habit?\"],\n",
        "            inputs=msg,\n",
        "            label=\"Denemek iÃ§in bir soru seÃ§in:\"\n",
        "        )\n",
        "\n",
        "        # ArayÃ¼z MantÄ±ÄŸÄ±\n",
        "        def user(user_message, history):\n",
        "            return \"\", history + [[user_message, None]]\n",
        "\n",
        "        def bot(history):\n",
        "            user_message = history[-1][0]\n",
        "            bot_message = get_neuro_coach_response(user_message, history[:-1])\n",
        "            history[-1][1] = bot_message\n",
        "            return history\n",
        "\n",
        "        msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
        "            bot, chatbot, chatbot\n",
        "        )\n",
        "\n",
        "# ArayÃ¼zÃ¼ BaÅŸlatma\n",
        "print(\"ArayÃ¼z baÅŸlatÄ±lÄ±yor...\")\n",
        "demo.launch(share=True, debug=True)\n",
        "\n",
        "# KapanmayÄ± Ã–nleme\n",
        "print(\"Gradio sunucusu aktif. Bu hÃ¼creyi canlÄ± tutmak iÃ§in Ã§alÄ±ÅŸmaya devam edecek.\")\n",
        "while True:\n",
        "    time.sleep(1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}